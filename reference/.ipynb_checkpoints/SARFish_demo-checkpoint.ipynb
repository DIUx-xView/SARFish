{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c73ea93-0901-4625-af4c-6f13ad6bbaf4",
   "metadata": {},
   "source": [
    "# SARFish dataset demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f9b654-b953-4ede-93c5-1c2f2d24172e",
   "metadata": {},
   "source": [
    "This jupyter notebook is designed to show new users how to get working with the SARFish dataset as quickly as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7319d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from GeoTiff import load_GeoTiff\n",
    "from visualise_labels import scale_sentinel_1_image, SARFish_Plot\n",
    "from SARFish_metric import score\n",
    "\n",
    "rng = np.random.default_rng(1234)\n",
    "\n",
    "%gui qt\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3088d4-3672-4fc8-88d5-0d873c130311",
   "metadata": {},
   "source": [
    "## Quick Links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f9fe6d-adf0-4114-9104-0fd7924c5fcb",
   "metadata": {},
   "source": [
    "The following are links to the Kaggle competitions for each of the tracks of the SARFish challenge along with the SARFish dataset and GitHub repo:\n",
    "\n",
    "- Data:\n",
    "    - [SARFish](https://huggingface.co/datasets/ConnorLuckettDSTG/SARFish)\n",
    "    - [SARFishSample](https://huggingface.co/datasets/ConnorLuckettDSTG/SARFishSample)\n",
    "- [Labels](https://iuu.xview.us/download-links)\n",
    "- Challenge:\n",
    "    - [Maritime Object Detection Track](https://www.kaggle.com/competitions/sarfish-maritime-object-detection) \n",
    "    - [Maritime Object Classification Track](https://www.kaggle.com/competitions/sarfish-maritime-object-classification)\n",
    "    - [Vessel Length Regression Track](https://www.kaggle.com/competitions/sarfish-vessel-length-regression)\n",
    "- [GitHub repo](https://github.com/RitwikGupta/SARFish)\n",
    "- [Mailbox](SARFish.Dataset@defence.gov.au)\n",
    "- [DAIRNet](https://www.dairnet.com.au/events/workshop-on-complex-valued-deep-learning-and-sarfish-challenge/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab362523-fb3c-4f2d-ae2f-4278c5de6af6",
   "metadata": {},
   "source": [
    "## What you will learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d6e222-ffcf-4694-bd68-b4ef253fc063",
   "metadata": {},
   "source": [
    "1. What is the SARFish Challenge?\n",
    "2. What is the SARFish dataset?\n",
    "3. How to access the SARFish dataset\n",
    "4. Dataset structure\n",
    "5. How to load and visualise the SARFish imagery data\n",
    "6. How to load and visualise the SARFish groundtruth labels\n",
    "7. How to train, validate and test the reference/baseline model\n",
    "8. SARFish challenge prediction submission format\n",
    "9. How to evaluate model performance using the SARFish metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd73c9f3-e3a2-4890-bd74-e17913298622",
   "metadata": {},
   "source": [
    "## 1. What is the SARFish Challenge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164d177c-8334-426d-8314-e866085643a4",
   "metadata": {},
   "source": [
    "The SARFish challenge aims to develop deep learning models for the detection, classification and length estimation of maritime objects in complex-valued [Single Look Complex (SLC)](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar/products-algorithms/level-1-algorithms/single-look-complex) [Synthetic Aperture Radar (SAR)](https://sentinel.esa.int/web/sentinel/missions/sentinel-1/instrument-payload) imagery data for the purpose of monitoring the activities of “dark” vessels engaged in [Illegal Unreported and Unregulated (IUU) fishing](https://globalfishingwatch.org/fisheries/iuu-illegal-unreported-unregulated-fishing/) practices. The SARFish challenge is inspired by the [xView3-SAR challenge](https://www.diu.mil/ai-xview-challenge) [2] which was released by [Global Fishing Watch (GFW)](https://globalfishingwatch.org/) and the [Defence Innovation Unit (DIU)](https://www.diu.mil/) in 2021 and adopts it's labels and performance metrics.\n",
    "\n",
    "IUU fishing is a global problem with severe ecological, economic, and political impacts. It primarily affects developing nations, many of which rely on regional fisheries as a major source of food and income. Maritime surveillance of fishing activities is a challenging task. First, the scale of the problem is staggering; in 2009, the extent of IUU fishing was estimated to constitute 20% of the world’s catch or between 11 and 26 million metric tons. Another challenge is the presence of dark vessels, so called because they disable their Automatic Identification Systems (AIS) broadcasts in “disabling events” to avoid reporting obligations and obscure their illicit activities. One solution to the problem of tracking dark vessels is to detect ships automatically from satellite imagery. SAR is an active imaging system that provides worldwide day-night and all-weather coverage of littoral regions suited to the task.\n",
    "\n",
    "[1]. Tri-Tan Cao, Connor Luckett, Jerome Williams, Tristrom Cooke, Ben Yip, Arvind Rajagopalan, and Sebastien Wong. Sarfish: Space-based maritime surveillance using complex synthetic aperture radar imagery. In 2022 International Conference on Digital Image Computing: Techniques and Applications (DICTA), pages 1–8. IEEE, 2022.\n",
    "\n",
    "[2] xview3-sar: Detecting dark fishing activity using synthetic aperture radar imagery. arXiv:2206.00897v4 [cs.CV], Nov 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c2c265-a61c-47c2-9c51-108a020c2377",
   "metadata": {},
   "source": [
    "### 1.2 Challenge Tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa69171-62c9-4dbc-bfc4-07fe65fc80d0",
   "metadata": {},
   "source": [
    "The SARFish challenge is divided into 3 tracks intended to align with the major challenges associated with the Monitoring, Control and Surveillance (MCS) of dark vessels:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb62dc6-ffac-4689-a4de-063f6beed9d6",
   "metadata": {},
   "source": [
    "#### [Maritime Object Detection](https://www.kaggle.com/competitions/sarfish-maritime-object-detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3a4b53-56cb-467e-be0d-e285d449b276",
   "metadata": {},
   "source": [
    "**Objective**: Locate maritime objects such as fishing vessels, oil rigs and offshore wind turbines in SARFish SLC imagery products. This track includes a close-to-shore detection task to assess model performance in the challenging task of detecting maritime objects within 2km of shorelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946ceb5-4af9-48e8-8cd1-8bb365b6ce11",
   "metadata": {},
   "source": [
    "#### [Maritime Object Classification](https://www.kaggle.com/competitions/sarfish-maritime-object-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644181a-65a8-4f69-a9a5-b2a7e6cc9419",
   "metadata": {},
   "source": [
    "**Objective**: Classify maritime objects as to whether or not they are vessels, and vessels as to whether or not they are fishing vessels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521af5ae-7d28-48ee-8afa-3e4b77f43dc6",
   "metadata": {},
   "source": [
    "### [Vessel Length Regression](https://www.kaggle.com/competitions/sarfish-vessel-length-regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc88c9-9e05-4a69-975e-7bd83372e43c",
   "metadata": {},
   "source": [
    "**Objective**: Predict the length of vessels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094b42e-0f5c-4a10-967b-4310aa817a1e",
   "metadata": {},
   "source": [
    "### 1.3 How to participate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c3674-68c5-4ac5-9977-61e3cd327a08",
   "metadata": {},
   "source": [
    "1. Download the SARFish dataset\n",
    "2. Use the train and validation partitions of the SARFish dataset to generate your model.\n",
    "3. Run inference over the entire public data partition outputing your predictions in submission format. \n",
    "4. Submit your predictions in csv format to the challenge track you wish to compete in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30d602-6a9b-4ea3-9a1a-1ca674a6df6a",
   "metadata": {},
   "source": [
    "## 2. What is the SARFish dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcb2135-268d-43fb-990f-3e276d9be339",
   "metadata": {},
   "source": [
    "### 2.1 Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2452e6d1-e39d-48a3-9759-c9b896671c3c",
   "metadata": {},
   "source": [
    "SARFish is an imagery dataset for the purpose of training, validating and testing supervised machine learning models on the tasks of ship detection, classification and vessel length regression. SARFish builds on the excellent work of the [xView3-SAR dataset](https://iuu.xview.us/dataset) by expanding the imagery data to include [Single Look Complex (SLC)](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar/products-algorithms/level-1-algorithms/single-look-complex) as well as [Ground Range Detected (GRD)](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar/products-algorithms/level-1-algorithms/ground-range-detected) imagery data taken directly from the European Space Agency \n",
    "(ESA) Copernicus Programme [Open Access Hub Website](https://scihub.copernicus.eu/).\n",
    "\n",
    "The following image shows a summarised description of the Sentinel-1 product family for the Interferrometric Wide (IW) mode. [^1] ![Sentinel-1 product processing pipeline summary](./images/sentinel_1_data_product_processing_levels_summary.jpg)\n",
    "\n",
    "[^1]: G. Hajduch, M. Bourbigot, H. Johnsen, and R. Piantanida, Sentinel-1 Product Specification. Sentinel-1 Mission Performance Centre, 2022, p. 34. [Online]. Available: [https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/document-library/-/asset_publisher/1dO7RF5fJMbd/content/id/4762447](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/document-library/-/asset_publisher/1dO7RF5fJMbd/content/id/4762447)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1054a6a-30f6-494b-be45-738c5d09ff14",
   "metadata": {},
   "source": [
    "### 2.2 The Sentinel-1 processing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042ed04-d71a-44e6-ad3f-a1c2b89a4515",
   "metadata": {},
   "source": [
    "The following diagram shows how the SARFish dataset extends the xView3-SAR dataset by providing the minimally pre-processed GRD and SLC counterparts to the xView3-SAR dataset imagery products and provides labels which have been re-projected labels into the pixel space of the images. ![Relationship between the xView3-SAR and SARFish datasets](./images/xView3-SAR_SARFish_dataset_relation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9867d3df-6c8c-412d-bd0a-5020e61025f5",
   "metadata": {},
   "source": [
    "### 2.3 Minimal SARFish processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07fbdb5-a067-43f9-8b0b-49af172d0f12",
   "metadata": {},
   "source": [
    "The preprocessing applied to the Sentinel-1 images to create the SARFish dataset was chosen in order to be minimally invasive. The preprocessing of the xView3-SAR dataset included radiometric calibration, decibel scaling, range doppler geocoding, projection to UTM using the [SeNtinel Application Platform (SNAP)](https://earth.esa.int/eogateway/tools/snap) [Graph Processing Tool](https://seadas.gsfc.nasa.gov/help-8.3.0/gpf/GraphProcessingTool.html). In contrast, the only operations applied to the SARFish data have been those necesary to make the images usable for computer vison tasks. The philosophy was to provide GRD and SLC data in a format as close as practicable to the Sentinel-1 data that can be downloaded from Copernicus.\n",
    "\n",
    "| Operation | xView3-SAR dataset | SARFish dataset |\n",
    "|-----------|--------------------|-----------------|\n",
    "| [radiometric-calibration](https://sentinels.copernicus.eu/web/sentinel/radiometric-calibration-of-level-1-products) | True | False |\n",
    "| [decibel scaling](https://en.wikipedia.org/wiki/Decibel) | True | False |\n",
    "| [range dopper geocoding](https://sentinel.esa.int/documents/247904/1653442/Guide-to-Sentinel-1-Geocoding.pdf)  | True | False |\n",
    "| [projection to UTM](https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system) | True | False |\n",
    "| flipping | True | True |\n",
    "| [de-bursting](https://sentinels.copernicus.eu/web/sentinel/level-1-post-processing-algorithms) | True | True |\n",
    "| [no data masking](https://gdal.org/development/rfc/rfc15_nodatabitmask.html) | True | True  |\n",
    "\n",
    "### Flipping:\n",
    "\n",
    "Flipping is applied to both GRD and SLC products. Sentinel-1 images are reflected with respect to the Earth's surface. This is due to the data aquisition method; first sensed azimuth lines are placed in the first rows in the image array. Images from both ascending and descending orbits will not map to the Earth's surface with a rotation, necessitating a flip along one axis. The images and ground control points (GCPS) are reversed along the range/x axis. \n",
    "\n",
    "### Debursting\n",
    "\n",
    "Debursting is applied only to SLC products. Sentinel-1 SLC products are provided as sets of 3 \"swaths\" per channel per scene. These swaths consist of \"sub-swaths\" or \"bursts\" which are overlapping segments of the image. The process of de-bursting is the alignment of these bursts into a contiguous image. This was done to create a one-to-one correspondence between the objects in each swath and the features on the Earth to which they correspond. It is important to note that as the deburst images are concatenations of bursts which themselves are individual SAR images, there are significant phase discontinuities on the boundaries of the bursts. It was decided for the purposes of this dataset that the bursts within the individual swaths should be merged rather than being split into seperate images.\n",
    "\n",
    "### No data masking\n",
    "\n",
    "No data masking is applied to both GRD and SLC products. Invalid pixels in the image have been masked using a nodata mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d1511-acb7-4190-ab7c-b76c07df3c86",
   "metadata": {},
   "source": [
    "## 3. Accessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9d2c8d-229f-43ca-a193-8bc643719d81",
   "metadata": {},
   "source": [
    "### 3.1 Downloading data from huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad9691-de20-4345-86e1-ea66716228e0",
   "metadata": {},
   "source": [
    "The SARFish dataset is available for download at:\n",
    "- [full SARFish dataset](https://huggingface.co/datasets/ConnorLuckettDSTG/SARFish)\n",
    "- [sample SARFish dataset](https://huggingface.co/datasets/ConnorLuckettDSTG/SARFishSample)\n",
    "\n",
    "| dataset       | coincident GRD, SLC products | compressed (GB) | uncompressed (GB) |\n",
    "| ------------- | ---------------------------- | --------------- | ----------------- |\n",
    "| SARFishSample | 1                            | 4.3             | 8.2               |\n",
    "| SARFish       | 753                          | 3293            | 6468              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62da0b15-1b17-489c-aeb8-35acf667aad3",
   "metadata": {},
   "source": [
    "#### Full SARFish dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2a7d85-52a1-475a-8dc9-8f0180c0757c",
   "metadata": {},
   "source": [
    "Make sure you have at least enough storage space for the uncompressed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953dcd98-6fb6-450e-bad5-a28f44c5daef",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd /path/to/large/storage/location\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec8d53-d447-4c3a-9ea4-b70b08111c40",
   "metadata": {},
   "source": [
    "[Create|login] to a [huggingface](https://huggingface.co) account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e5c38-589b-44a0-adc5-0aa1040baa92",
   "metadata": {},
   "source": [
    "Login to the huggingface command line interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9dc241-7e1a-4a2e-a9c1-d705f52cba91",
   "metadata": {},
   "source": [
    "```bash\n",
    "huggingface-cli login\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd0954c-21f0-484a-9c4c-e095686923f0",
   "metadata": {},
   "source": [
    "Copy the access token in settings/Access Tokens from your huggingface account. Clone the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a037cd0-845e-46a7-b9eb-97615f9d1d43",
   "metadata": {},
   "source": [
    "```bash\n",
    "git lfs install\n",
    "git clone https://huggingface.co/datasets/ConnorLuckettDSTG/SARFish\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f785c85-d6ab-42c0-acb2-40e6a841d1d7",
   "metadata": {},
   "source": [
    "#### SARFish sample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6072a4-c21a-4221-98a4-141f5cfef173",
   "metadata": {},
   "source": [
    "Substitute the final command for the full dataset with the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dd9dc1-f721-4b86-929f-462dc8665215",
   "metadata": {},
   "source": [
    "```bash\n",
    "git clone https://huggingface.co/datasets/ConnorLuckettDSTG/SARFishSample\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3ab481-ee20-4198-9513-6ba71e32cf96",
   "metadata": {},
   "source": [
    "### 3.2 Checking the md5sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a55f3f7-905e-4d79-ac6d-90b7b77cfb06",
   "metadata": {},
   "source": [
    "Use the provided sum checking functionn to check the md5 sums of the downloaded SARFish products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7460072-1a61-4b37-8f64-e943afc6edb7",
   "metadata": {},
   "source": [
    "```bash\n",
    "./check_SARFish_md5sum.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f522804-e444-4d80-9118-2a52b0d961a2",
   "metadata": {},
   "source": [
    "### 3.3 Unizipping the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ae607-4e30-455b-9855-b55b6c7a12e4",
   "metadata": {},
   "source": [
    "Use the provided unzipping function to unzip the SARFish data products in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5301422a-1ea9-422f-8419-f43972256f60",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd /path/to/SARFish/directory/GRD\n",
    "unzip\\_batch.sh -p $(find './' -type f -name \"*.SAFE.zip\")\n",
    "\n",
    "cd /path/to/SARFish/directory/SLC\n",
    "unzip\\_batch.sh -p $(find './' -type f -name \"*.SAFE.zip\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc6de6a-c07b-460c-a38b-fa49db5cd9c4",
   "metadata": {},
   "source": [
    "### 3.4 Setting the SARFish dataset root directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce3e35-3e21-4a34-9feb-b807c93a82ed",
   "metadata": {},
   "source": [
    "Modify the environment.yaml file in this directory and substitude the dummy path with the SARFish root directory. For example; if your local copy of the SARFish dataset resides in /data/SARFish, subsitute /path/to/SARFish/root/ with /data/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b8e4e-494c-42fa-894b-67d2291acfe5",
   "metadata": {},
   "source": [
    "```\n",
    "SARFISH_ROOT_DIRECTORY: /path/to/SARFish/root/ \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d95fd6d2-a24a-4393-8507-1c6876fca555",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"environment.yaml\", \"r\") as f:\n",
    "    environment = yaml.safe_load(f)\n",
    "\n",
    "SARFish_root_directory = environment['SARFish_root_directory']\n",
    "os.environ['SARFISH_ROOT_DIRECTORY'] = SARFish_root_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e4e71c-2f2e-478e-b7e5-3469d3964fe5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The SARFish dataset is packaged in the [SAFE format](https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-1-sar/data-formats/safe-specification). The product file name consists of the unique [product identifier](https://sentinel.esa.int/documents/247904/1877131/Sentinel-1-Product-Specification) (section 3.5.1) from which the SARFish product was derived.\n",
    "\n",
    "The following tree shows an overview of the SARFish dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df47602-2d80-4d99-8eac-b0c9f853a3b0",
   "metadata": {},
   "source": [
    "```\n",
    "SARFish/\n",
    "├── GRD\n",
    "│   ├── public\n",
    "│   │   └── S1B_IW_GRDH_1SDV_*.SAFE\n",
    "│   ├── train\n",
    "│   │   └── S1B_IW_GRDH_1SDV_*.SAFE\n",
    "│   └── validation\n",
    "│       └── S1B_IW_GRDH_1SDV_*.SAFE\n",
    "└── SLC\n",
    "    ├── public\n",
    "    │   └── S1B_IW_SLC__1SDV_*.SAFE\n",
    "    ├── train\n",
    "    │   └── S1B_IW_SLC__1SDV_*.SAFE\n",
    "    └── validation\n",
    "        └── S1B_IW_SLC__1SDV_*.SAFE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83cb4b3-92b5-42cd-a570-6ef79c85aff0",
   "metadata": {},
   "source": [
    "## 4. Dataset Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fb6d4a-1b2b-4013-bf5f-58ebab456aef",
   "metadata": {},
   "source": [
    "### 4.1 Dataset Partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0665fb45-6d7c-4773-9e53-ccde33a3175b",
   "metadata": {},
   "source": [
    "The partitions of the dataset are as follows:\n",
    "\n",
    "| partition   | labels provided |\n",
    "| ----------- | --------------- |\n",
    "| train       | True            |\n",
    "| validation  | True            |\n",
    "| public      | False           |\n",
    "\n",
    "The public partition is provided with no labels. It will to be used to determine competitor's ranking in the SARFish challenge. Competitors will run their model over the public partition of the dataset producing predictions for each constituent scene and submit these in the submisson format (see section 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7550a01-bf9d-4995-a477-18a4cc1f4e4a",
   "metadata": {},
   "source": [
    "### 4.2 The two SARFish product types: GRD and SLC\n",
    "\n",
    "The SARFish dataset consists of pairs of coincident [real-valued GRD and complex valued SLC](https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-1-sar/product-types-processing-levels/level-1) imagery products from the Sentinel-1 satellite constellation. The GRD and SLC designations are the **product\\_type**. The mapping between xView3-SAR **scene\\_id** and the [Copernicus](https://www.copernicus.eu/en) product identifier is contained in the xView3\\_SLC\\_GRD\\_correspondences.csv file. The following cell shows an example of the mapping between xView3-SAR and SARFish GRD, SLC products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7218a51a-a7ce-409e-a8cb-3c6601fa0f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_id</th>\n",
       "      <th>GRD_product_identifier</th>\n",
       "      <th>SLC_product_identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>5c3d986db930f848v</td>\n",
       "      <td>S1B_IW_GRDH_1SDV_20200803T075721_20200803T0757...</td>\n",
       "      <td>S1B_IW_SLC__1SDV_20200803T075720_20200803T0757...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              scene_id                             GRD_product_identifier  \\\n",
       "703  5c3d986db930f848v  S1B_IW_GRDH_1SDV_20200803T075721_20200803T0757...   \n",
       "\n",
       "                                SLC_product_identifier  \n",
       "703  S1B_IW_SLC__1SDV_20200803T075720_20200803T0757...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xView3_SLC_GRD_correspondences = pd.read_csv(\"./labels/xView3_SLC_GRD_correspondences.csv\")\n",
    "xView3_SLC_GRD_correspondences[['scene_id', 'GRD_product_identifier', 'SLC_product_identifier']].iloc[703:704]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de840bf-6f1d-4ecd-b732-9311d7030c3b",
   "metadata": {},
   "source": [
    "The xView3\\_SLC\\_GRD\\_correspondences.csv file also contains the file names of the vh, vh imagery products and their associated annotation.xml files. This is used to pick out individual imagery data for processing and evalutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a00722e-fc13-43d3-b8dd-8cabb7c23a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 753 entries, 0 to 752\n",
      "Data columns (total 22 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   DATA_PARTITION             753 non-null    object\n",
      " 1   scene_id                   753 non-null    object\n",
      " 2   GRD_product_identifier     753 non-null    object\n",
      " 3   GRD_md5sum                 753 non-null    object\n",
      " 4   GRD_vh                     753 non-null    object\n",
      " 5   GRD_vv                     753 non-null    object\n",
      " 6   GRD_vh_annotation          753 non-null    object\n",
      " 7   GRD_vv_annotation          753 non-null    object\n",
      " 8   SLC_product_identifier     753 non-null    object\n",
      " 9   SLC_md5sum                 753 non-null    object\n",
      " 10  SLC_swath_1_vh             753 non-null    object\n",
      " 11  SLC_swath_1_vv             753 non-null    object\n",
      " 12  SLC_swath_1_vh_annotation  753 non-null    object\n",
      " 13  SLC_swath_1_vv_annotation  753 non-null    object\n",
      " 14  SLC_swath_2_vh             753 non-null    object\n",
      " 15  SLC_swath_2_vv             753 non-null    object\n",
      " 16  SLC_swath_2_vh_annotation  753 non-null    object\n",
      " 17  SLC_swath_2_vv_annotation  753 non-null    object\n",
      " 18  SLC_swath_3_vh             753 non-null    object\n",
      " 19  SLC_swath_3_vv             753 non-null    object\n",
      " 20  SLC_swath_3_vh_annotation  753 non-null    object\n",
      " 21  SLC_swath_3_vv_annotation  753 non-null    object\n",
      "dtypes: object(22)\n",
      "memory usage: 129.6+ KB\n"
     ]
    }
   ],
   "source": [
    "xView3_SLC_GRD_correspondences.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4089c6dc-5024-4fb9-9bbf-40ea7931b949",
   "metadata": {},
   "source": [
    "### 4.3 SARFish dataset format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e429a23-39c5-4047-bc73-0f17b6bba14d",
   "metadata": {},
   "source": [
    "#### GRD imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b454-fc36-4736-9d4a-23cb5ec55023",
   "metadata": {},
   "source": [
    "GRD products are uniquely identified by their:\n",
    "\n",
    "- product\\_type\n",
    "- partition \n",
    "- GRD\\_product\\_identifier\n",
    "- polarisation \n",
    "\n",
    "The tree of an example SARFish GRD Product:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450339d3-0070-4974-9c94-0aa652569187",
   "metadata": {},
   "source": [
    "```\n",
    "SARFish/GRD/validation/S1B_IW_GRDH_1SDV_20201013T054010_20201013T054035_023790_02D350_506A.SAFE/\n",
    "├── annotation\n",
    "│   └── ...\n",
    "├── manifest.safe\n",
    "├── measurement <- imagery data\n",
    "│   ├── S1B_IW_GRDH_1SDV_20201013T054010_20201013T054035_023790_02D350_506A_global_shoreline_vector.npy\n",
    "│   ├── S1B_IW_GRDH_1SDV_20201013T054010_20201013T054035_023790_02D350_506A_xView3_shoreline.npy\n",
    "│   ├── s1b-iw-grd-vh-20201013t054010-20201013t054035-023790-02d350-002_SARFish.tiff\n",
    "│   └── s1b-iw-grd-vv-20201013t054010-20201013t054035-023790-02d350-001_SARFish.tiff\n",
    "├── preview\n",
    "│   └── ...\n",
    "├── ...\n",
    "└── support\n",
    "    └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a842d6cb-6240-4376-a774-c32083b9efb1",
   "metadata": {},
   "source": [
    "The imagery data located in \"measurement\" consists of 2 images containing the polarimetic channels called VV, VH polarisations packaged in the GeoTiff format. Also included in the measurement folder are numpy archives which contain shoreline vectors which are used in the evaluation of a model's close-to-shore detection performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d453ffc5-2345-4428-bfee-bc8e07efa679",
   "metadata": {},
   "source": [
    "#### SLC imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ba2eab-9f8a-4937-9d14-bc22f3cf3cb2",
   "metadata": {},
   "source": [
    "SLC products are uniquely identified by their:\n",
    "\n",
    "- product\\_type\n",
    "- partition \n",
    "- GRD\\_product\\_identifier\n",
    "- polarisation\n",
    "- swath\\_index\n",
    "\n",
    "The tree of an example SARFish SLC Product:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b66c9d5-ea22-4ff6-93e3-b5b0ae577e22",
   "metadata": {},
   "source": [
    "```\n",
    "SARFish/SLC/validation/S1B_IW_SLC__1SDV_20201013T054008_20201013T054035_023790_02D350_04D0.SAFE\n",
    "├── annotation\n",
    "│   └── ...\n",
    "├── manifest.safe\n",
    "├── measurement\n",
    "│   ├── s1b-iw1-slc-vh-20201013t054009-20201013t054034-023790-02d350-001_SARFish.tiff                 <- swath 1 image data\n",
    "│   ├── s1b-iw1-slc-vh-20201013t054009-20201013t054034-023790-02d350-001_SARFish.tiff.msk             <- swath 1 image mask\n",
    "│   ├── s1b-iw1-slc-vv-20201013t054009-20201013t054034-023790-02d350-004_SARFish.tiff\n",
    "│   ├── s1b-iw1-slc-vv-20201013t054009-20201013t054034-023790-02d350-004_SARFish.tiff.msk\n",
    "│   ├── s1b-iw2-slc-vh-20201013t054010-20201013t054035-023790-02d350-002_SARFish.tiff\n",
    "│   ├── s1b-iw2-slc-vh-20201013t054010-20201013t054035-023790-02d350-002_SARFish.tiff.msk\n",
    "│   ├── s1b-iw2-slc-vv-20201013t054010-20201013t054035-023790-02d350-005_SARFish.tiff\n",
    "│   ├── s1b-iw2-slc-vv-20201013t054010-20201013t054035-023790-02d350-005_SARFish.tiff.msk\n",
    "│   ├── s1b-iw3-slc-vh-20201013t054008-20201013t054033-023790-02d350-003_SARFish.tiff\n",
    "│   ├── s1b-iw3-slc-vh-20201013t054008-20201013t054033-023790-02d350-003_SARFish.tiff.msk\n",
    "│   ├── s1b-iw3-slc-vv-20201013t054008-20201013t054033-023790-02d350-006_SARFish.tiff\n",
    "│   ├── s1b-iw3-slc-vv-20201013t054008-20201013t054033-023790-02d350-006_SARFish.tiff.msk\n",
    "│   ├── S1B_IW_SLC__1SDV_20201013T054008_20201013T054035_023790_02D350_04D0_1_global_shoreline_vector.npy  <- swath 1 global shoreline vector\n",
    "│   ├── S1B_IW_SLC__1SDV_20201013T054008_20201013T054035_023790_02D350_04D0_1_xView3_shoreline.npy         <- swath 1 xView3 shoreline vector\n",
    "│   ├── S1B_IW_SLC__1SDV_20201013T054008_20201013T054035_023790_02D350_04D0_2_global_shoreline_vector.npy\n",
    "│   ├── S1B_IW_SLC__1SDV_20201013T054008_20201013T054035_023790_02D350_04D0_2_xView3_shoreline.npy\n",
    "│   ├── S1B_IW_SLC__1SDV_20201013T054008_20201013T054035_023790_02D350_04D0_3_global_shoreline_vector.npy\n",
    "│   └── S1B_IW_SLC__1SDV_20201013T054008_20201013T054035_023790_02D350_04D0_3_xView3_shoreline.npy\n",
    "├── preview\n",
    "│   └── ...\n",
    "├── ...\n",
    "└── support\n",
    "    └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ea7a1-3bb1-4b44-bdd6-c0d5e77a7fc1",
   "metadata": {},
   "source": [
    "The imagery data located in the \"measurement\" directory consists of 3 sets (swaths) of 2 images containing the polarimetric channels called VV, VH packaged in the GeoTiff. Each Sentinel-1 SLC product is the composite of 3 swaths. The process of [debursting](https://github.com/senbox-org/s1tbx/blob/master/s1tbx-op-sentinel1-ui/src/main/resources/org/esa/s1tbx/sentinel1/docs/operators/TOPSARDeburstOp.html) has been applied to each swath, but the swaths have not been merged. Each SLC swath is again accompanied by a corresponding xView3-SAR and global shoreline vector. In addition corresponding [.msk](https://gdal.org/development/rfc/rfc15_nodatabitmask.html) (mask) files are used by the GeoTiff.load\\_Geotiff function in order to mask the no-data portions of the SLC products. The function load_Geotiff allow a user to easily load both GRD and SLC SARFish products taking into account their respective masks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274924db-78ad-4672-8e25-ae66e166a527",
   "metadata": {},
   "source": [
    "## 5. How to load and visualise the SARFish imagery data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2e27e5-3a7d-4fca-8bb3-298cc1441110",
   "metadata": {},
   "source": [
    "To generate the path to the GRD and SLC products associated with a single scene, we first we pick out a specific row from the xView3_SLC_GRD_correspondence table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f0aded9-a06b-4aec-bbaa-5a128759745b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATA_PARTITION                                                      validation\n",
       "scene_id                                                     5c3d986db930f848v\n",
       "GRD_product_identifier       S1B_IW_GRDH_1SDV_20200803T075721_20200803T0757...\n",
       "GRD_md5sum                                    3f8ec460304f087c8f9a59b7c0897561\n",
       "GRD_vh                       s1b-iw-grd-vh-20200803t075721-20200803t075746-...\n",
       "GRD_vv                       s1b-iw-grd-vv-20200803t075721-20200803t075746-...\n",
       "GRD_vh_annotation            s1b-iw-grd-vh-20200803t075721-20200803t075746-...\n",
       "GRD_vv_annotation            s1b-iw-grd-vv-20200803t075721-20200803t075746-...\n",
       "SLC_product_identifier       S1B_IW_SLC__1SDV_20200803T075720_20200803T0757...\n",
       "SLC_md5sum                                    c32f40b7d3a1304a30c287d7eae75684\n",
       "SLC_swath_1_vh               s1b-iw1-slc-vh-20200803t075720-20200803t075748...\n",
       "SLC_swath_1_vv               s1b-iw1-slc-vv-20200803t075720-20200803t075748...\n",
       "SLC_swath_1_vh_annotation    s1b-iw1-slc-vh-20200803t075720-20200803t075748...\n",
       "SLC_swath_1_vv_annotation    s1b-iw1-slc-vv-20200803t075720-20200803t075748...\n",
       "SLC_swath_2_vh               s1b-iw2-slc-vh-20200803t075721-20200803t075746...\n",
       "SLC_swath_2_vv               s1b-iw2-slc-vv-20200803t075721-20200803t075746...\n",
       "SLC_swath_2_vh_annotation    s1b-iw2-slc-vh-20200803t075721-20200803t075746...\n",
       "SLC_swath_2_vv_annotation    s1b-iw2-slc-vv-20200803t075721-20200803t075746...\n",
       "SLC_swath_3_vh               s1b-iw3-slc-vh-20200803t075722-20200803t075747...\n",
       "SLC_swath_3_vv               s1b-iw3-slc-vv-20200803t075722-20200803t075747...\n",
       "SLC_swath_3_vh_annotation    s1b-iw3-slc-vh-20200803t075722-20200803t075747...\n",
       "SLC_swath_3_vv_annotation    s1b-iw3-slc-vv-20200803t075722-20200803t075747...\n",
       "Name: 703, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correspondence = xView3_SLC_GRD_correspondences.iloc[703:704].squeeze()\n",
    "correspondence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13380d6-9a9e-4e81-af03-4b35915cbc77",
   "metadata": {},
   "source": [
    "### 5.1 Loading GRD imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d258040-b769-49af-be28-529bc86362ab",
   "metadata": {},
   "source": [
    "The correspondence mapping is used to generate the specific GRD product path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31d760ef-82d7-4f23-8b15-1d3c6e7e2a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/datasets/SARFishSample/GRD/validation/S1B_IW_GRDH_1SDV_20200803T075721_20200803T075746_022756_02B2FF_033A.SAFE/measurement/s1b-iw-grd-vh-20200803t075721-20200803t075746-022756-02b2ff-002_SARFish.tiff'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurement_path_GRD = Path(\n",
    "    SARFish_root_directory, \"GRD\", correspondence['DATA_PARTITION'], f\"{correspondence['GRD_product_identifier']}.SAFE\",\n",
    "    \"measurement\", correspondence[f'GRD_vh']\n",
    ")\n",
    "str(measurement_path_GRD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ff9b9a-7043-45ce-88ad-2a44e7d1e535",
   "metadata": {},
   "source": [
    "The image is loaded into numpy arrays using the provided GeoTiff.load_Geotiff function. The function returns an array of image data, and a second array masking the no data areas. Since the data is in linear scale, we use the provided scaling function visualise\\_labels.scale_sentinel\\_1\\_image to convert the data to a decibel scale which is more easily interpereted by humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d61de9-51c2-45d6-8e0c-4c7dd0b42752",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GRD, nodata_mask_GRD, _, _ = load_GeoTiff(str(measurement_path_GRD))\n",
    "scaled_data_GRD = scale_sentinel_1_image(data_GRD, nodata_mask_GRD, product_type = \"GRD\")\n",
    "data_GRD = None\n",
    "clipped_scaled_data_GRD = np.clip(scaled_data_GRD, 10, 30)\n",
    "scaled_data_GRD = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e155b-b6b4-42f1-a826-0e9cf9642986",
   "metadata": {},
   "source": [
    "### 5.2 Plotting GRD imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0fcf5c-0114-4024-9b7e-11cc4cdcea46",
   "metadata": {},
   "source": [
    "The data can be plotted using the provided SARFish\\_Plot class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf417285-b1e2-4a9d-b859-653cb3d84abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: could not determine DPI\n"
     ]
    }
   ],
   "source": [
    "plot_GRD = SARFish_Plot(\n",
    "    clipped_scaled_data_GRD, nodata_mask_GRD, title = f\"example plotting groundtruth labels in {correspondence[f'GRD_product_identifier']}\", \n",
    ")\n",
    "nodata_mask_GRD = None\n",
    "clipped_scaled_data_GRD = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df89b092-513d-4593-a051-380ba8457e2c",
   "metadata": {},
   "source": [
    "### 5.3 Plotting SLC imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121abd6f-5289-45a2-ad26-821562395789",
   "metadata": {},
   "source": [
    "There are three SLC swaths per product. We will load and visualise the imagery in one cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da94872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: could not determine DPI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLC swath 1 loading time: 26.839911699295044 seconds.\n",
      "SLC swath 2 loading time: 44.60941743850708 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: could not determine DPI\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m      5\u001b[0m measurement_path_SLC \u001b[38;5;241m=\u001b[39m Path(\n\u001b[1;32m      6\u001b[0m     SARFish_root_directory, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSLC\u001b[39m\u001b[38;5;124m\"\u001b[39m, correspondence[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATA_PARTITION\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrespondence[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSLC_product_identifier\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.SAFE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeasurement\u001b[39m\u001b[38;5;124m\"\u001b[39m, correspondence[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSLC_swath_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mswath_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_vh\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m data_SLC, nodata_mask_SLC, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mload_GeoTiff\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmeasurement_path_SLC\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m scaled_data_SLC \u001b[38;5;241m=\u001b[39m scale_sentinel_1_image(data_SLC, nodata_mask_SLC, product_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSLC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m data_SLC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/work/sarfish-integrate_bens_FCOS_model_2023_12_22/sarfish-integrate_bens_FCOS_model/reference/GeoTiff.py:85\u001b[0m, in \u001b[0;36mload_GeoTiff\u001b[0;34m(image_filepath)\u001b[0m\n\u001b[1;32m     81\u001b[0m number_of_data_band_rows, number_of_data_band_columns \u001b[38;5;241m=\u001b[39m get_band_shape(\n\u001b[1;32m     82\u001b[0m     data_band\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     84\u001b[0m data_band_data_type_enum \u001b[38;5;241m=\u001b[39m data_band\u001b[38;5;241m.\u001b[39mDataType\n\u001b[0;32m---> 85\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata_band\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReadAsArray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_data_band_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_data_band_rows\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_band\u001b[38;5;241m.\u001b[39mGetNoDataValue() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     nodata_value \u001b[38;5;241m=\u001b[39m data_band\u001b[38;5;241m.\u001b[39mGetNoDataValue()\n",
      "File \u001b[0;32m~/Documents/work/sarfish-integrate_bens_FCOS_model_2023_12_22/sarfish-integrate_bens_FCOS_model/venv/lib64/python3.11/site-packages/osgeo/gdal.py:3745\u001b[0m, in \u001b[0;36mBand.ReadAsArray\u001b[0;34m(self, xoff, yoff, win_xsize, win_ysize, buf_xsize, buf_ysize, buf_type, buf_obj, resample_alg, callback, callback_data)\u001b[0m\n\u001b[1;32m   3740\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Reading a chunk of a GDAL band into a numpy array. The optional (buf_xsize,buf_ysize,buf_type)\u001b[39;00m\n\u001b[1;32m   3741\u001b[0m \u001b[38;5;124;03mparameters should generally not be specified if buf_obj is specified. The array is returned\"\"\"\u001b[39;00m\n\u001b[1;32m   3743\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mosgeo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gdal_array\n\u001b[0;32m-> 3745\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgdal_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBandReadAsArray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3746\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mwin_xsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_ysize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3747\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mbuf_xsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf_ysize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3748\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mresample_alg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample_alg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3749\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3750\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mcallback_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/work/sarfish-integrate_bens_FCOS_model_2023_12_22/sarfish-integrate_bens_FCOS_model/venv/lib64/python3.11/site-packages/osgeo/gdal_array.py:450\u001b[0m, in \u001b[0;36mBandReadAsArray\u001b[0;34m(band, xoff, yoff, win_xsize, win_ysize, buf_xsize, buf_ysize, buf_type, buf_obj, resample_alg, callback, callback_data)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecified buf_type not consistent with array type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    448\u001b[0m     buf_type \u001b[38;5;241m=\u001b[39m datatype\n\u001b[0;32m--> 450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mBandRasterIONumPy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mband\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_xsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_ysize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mbuf_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample_alg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_data\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    452\u001b[0m     _RaiseException()\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/work/sarfish-integrate_bens_FCOS_model_2023_12_22/sarfish-integrate_bens_FCOS_model/venv/lib64/python3.11/site-packages/osgeo/gdal_array.py:111\u001b[0m, in \u001b[0;36mBandRasterIONumPy\u001b[0;34m(band, bWrite, xoff, yoff, xsize, ysize, psArray, buf_type, resample_alg, callback, callback_data)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mBandRasterIONumPy\u001b[39m(band, bWrite, xoff, yoff, xsize, ysize, psArray, buf_type, resample_alg, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, callback_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"BandRasterIONumPy(Band band, int bWrite, double xoff, double yoff, double xsize, double ysize, PyArrayObject * psArray, GDALDataType buf_type, GDALRIOResampleAlg resample_alg, GDALProgressFunc callback=0, void * callback_data=None) -> CPLErr\"\"\"\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_gdal_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBandRasterIONumPy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mband\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbWrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mysize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsArray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample_alg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SLC_plots = []\n",
    "for swath_index in [1, 2, 3]:\n",
    "    start = time()\n",
    "    \n",
    "    measurement_path_SLC = Path(\n",
    "        SARFish_root_directory, \"SLC\", correspondence['DATA_PARTITION'], f\"{correspondence['SLC_product_identifier']}.SAFE\",\n",
    "        \"measurement\", correspondence[f'SLC_swath_{swath_index}_vh']\n",
    "    )\n",
    "    \n",
    "    data_SLC, nodata_mask_SLC, _, _ = load_GeoTiff(str(measurement_path_SLC))\n",
    "    scaled_data_SLC = scale_sentinel_1_image(data_SLC, nodata_mask_SLC, product_type = \"SLC\")\n",
    "    data_SLC = None\n",
    "    clipped_scaled_data_SLC = np.clip(scaled_data_SLC, 15, 60)\n",
    "    scaled_data_SLC = None\n",
    "    \n",
    "    stop = time()\n",
    "    print(f\"SLC swath {swath_index} loading time: {stop - start} seconds.\")\n",
    "\n",
    "    plot_SLC = SARFish_Plot(\n",
    "        clipped_scaled_data_SLC, nodata_mask_SLC,\n",
    "        title = f\"example plotting groundtruth labels in {correspondence['SLC_product_identifier']}, swath: {swath_index}\"\n",
    "    )\n",
    "    SLC_plots.append(plot_SLC)\n",
    "    nodata_mask_SLC = None\n",
    "    clipped_scaled_data_SLC = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ef724-d0d0-4814-94d2-793d27e0e9a2",
   "metadata": {},
   "source": [
    "## 6. How to load and visualise the SARFish labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40d31d-05d6-43d9-aa43-7c060c97cff3",
   "metadata": {},
   "source": [
    "The groundtruth labels for the SARFish dataset are aranged similarly to the xView3-SAR dataset. The labels contain the location, classification and length of each maritime object present in all scenes for a particular product type and dataset partition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c870635d-f043-40d3-9c9f-a2044c3d1d14",
   "metadata": {},
   "source": [
    "### 6.1 Label Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f2e1c6-db62-4804-a1a3-dc71a1967b81",
   "metadata": {},
   "source": [
    "#### Location labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86738b4c-65d2-4c26-8698-a0bfa3ff34e1",
   "metadata": {},
   "source": [
    "The labels denote the image pixel and geographic coordinate location of the maritime object.\n",
    "\n",
    "| field     | data_type | description |\n",
    "| --------- | ----------- | --------- |\n",
    "| detect\\_lat | float | latitude of detection in World Geodetic System (WGS) 84 coordinates |\n",
    "| detect\\_lon | float | longitude of detection in WGS84 coordinates |\n",
    "| detect\\_scene\\_row | int | pixel row of scene containing detection |\n",
    "| detect\\_scene\\_column | int | pixel column of scene containing detection |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e2e71b-c01a-4559-bebf-197e4ff205c9",
   "metadata": {},
   "source": [
    "#### Classification Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f159d-4f8b-4dca-883f-434aec3e1258",
   "metadata": {},
   "source": [
    "The labels for the maritime object classification are organised in the same hierarchical structure as the xView3-SAR challenge labels:\n",
    "\n",
    "```bash\n",
    "label_heirarchy:\n",
    "└── maritime_objects\n",
    "    └── vessels\n",
    "        └── fishing_vessels\n",
    "```\n",
    "\n",
    "They are denoted by the following columns in the labels:\n",
    "\n",
    "| field     | data_type | description |\n",
    "| --------- | ----------- | --------- |\n",
    "| is\\_vessel | bool | True if detection is a vessel, False otherwise |\n",
    "| is\\_fishing | bool | True if detection is a fishing vessel, False otherwise |\n",
    "\n",
    "The maritime object categories are labelled using boolean values to the following questions:\n",
    "\n",
    "- is the maritime object a vessel?\n",
    "- is the vessel a fishing vessel?\n",
    "\n",
    "The following table shows the combinations of hierarchical classification labels present in the SARFish dataset:\n",
    "\n",
    "| is\\_vessel | is\\_fishing |\n",
    "|------------:|-------------:|\n",
    "| False | nan |\n",
    "| True | nan |\n",
    "| | False |\n",
    "| | True |\n",
    "| nan | nan |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e01a6e-9429-450f-9cbd-6bd665b4be30",
   "metadata": {},
   "source": [
    "#### Vessel Length Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7eaf85-2214-43fd-9d8b-ae3adaa3ba63",
   "metadata": {},
   "source": [
    "The vessel lengths are denoted in the following column in the labels:\n",
    "\n",
    "| field     | data_type | description |\n",
    "| --------- | ----------- | --------- |\n",
    "| vessel\\_length\\_m | float | length of vessel in meters; only provided where available from AIS |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5905512-2a3d-4bd6-83ee-b8418a2db357",
   "metadata": {},
   "source": [
    "The full groundtruth label attributes are detailed in the table below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed1e86f-4b49-40df-843a-bf66c377fd2d",
   "metadata": {},
   "source": [
    "| field     | data_type | description |\n",
    "| --------- | ----------- | --------- |\n",
    "| partition | str: \\{\"train\", \"validation\"\\} | split of the dataset |\n",
    "| product\\_type | str: \\{\"GRD\", \"SLC\"\\} | product type of the data |\n",
    "| scene\\_id | str | unique xView3 scene ID for challenge purposes |\n",
    "| detect\\_id | str | unique detection ID in format scene\\_id\\_detect\\_lat\\_detect\\_lon |\n",
    "| \\{product\\_type\\}\\_product\\_identifier | str | The copernicus Sentinel-1 product identifier for the designated product type |\n",
    "| detect\\_lat | float | latitude of detection in World Geodetic System (WGS) 84 coordinates |\n",
    "| detect\\_lon | float | longitude of detection in WGS84 coordinates |\n",
    "| detect\\_scene\\_row | int | pixel row of scene containing detection |\n",
    "| detect\\_scene\\_column | int | pixel column of scene containing detection |\n",
    "| top | float | pixel row of the top left corner of the bounding box, where available |\n",
    "| left | float | pixel column of the top left corner of the bounding box, where available |\n",
    "| bottom | float | pixel row of the bottom right corner of the bounding box, where available |\n",
    "| right | float | pixel column of the bottom right corner of the bounding box, where available |\n",
    "| vessel\\_length\\_m | float | length of vessel in meters; only provided where available from AIS |\n",
    "| source | str: \\{AIS, AIS/Manual, Manual\\} | source of detection (AIS, manual label, or both) |\n",
    "| is\\_vessel | bool | True if detection is a vessel, False otherwise |\n",
    "| is\\_fishing | bool | True if detection is a fishing vessel, False otherwise |\n",
    "| global\\_shoreline\\_vector\\_distance\\_from\\_shore\\_km | float | distance from shore of detection in kilometers as determined using the global shoreline vectors projected into the pixel space of the SARFish products  |\n",
    "| xView3\\_shoreline\\_vector\\_distance\\_from\\_shore\\_km | float | distance from shore of detection in kilometers as determined using the  xView3-SAR shoreline vectors projected into the pixel space of the SARFish products  |\n",
    "| confidence | str: \\{HIGH, MEDIUM, LOW\\} | level of confidence for is\\_vessel and is\\_fishing labels |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e376e-b887-43af-9d81-8ff6d94e4ec7",
   "metadata": {},
   "source": [
    "### 6.1 Loading and visualising GRD groundtruth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d446e5-1377-4088-97e4-dbef01dc7398",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_GRD = pd.read_csv(\n",
    "    str(\n",
    "        Path(SARFish_root_directory, \"GRD\", correspondence['DATA_PARTITION'], f\"GRD_{correspondence['DATA_PARTITION']}.csv\")\n",
    "    )\n",
    ")\n",
    "groundtruth_GRD = groundtruth_GRD[groundtruth_GRD['GRD_product_identifier'] == correspondence['GRD_product_identifier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14419bcd-bd89-4f7a-bb09-2a2c9d607f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_GRD.add_bboxes(groundtruth_GRD[['left', 'right', 'bottom', 'top']])\n",
    "plot_GRD.add_labels(\n",
    "    columns = groundtruth_GRD['detect_scene_column'], rows = groundtruth_GRD['detect_scene_row'], \n",
    "    categories = groundtruth_GRD[['detect_id', 'is_vessel', 'is_fishing', 'vessel_length_m', 'confidence']], \n",
    "    legend_label = \"groundtruth\", color = \"yellow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce190060-0926-43ac-9d08-e00c1e01a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_GRD.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16244e49-b7aa-48c9-aef6-29170b9b6b8e",
   "metadata": {},
   "source": [
    "### 6.2 Loading and visualising SLC groundtruth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2b5a11-5ea0-4f0f-881f-01fde0cc0b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_SLC = pd.read_csv(\n",
    "    str(\n",
    "        Path(SARFish_root_directory, \"SLC\", correspondence['DATA_PARTITION'], f\"SLC_{correspondence['DATA_PARTITION']}.csv\")\n",
    "    )\n",
    ")\n",
    "groundtruth_SLC = groundtruth_SLC[groundtruth_SLC['SLC_product_identifier'] == correspondence['SLC_product_identifier']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc1bcc9-3d5c-415f-9db0-c70a0ef1b99d",
   "metadata": {},
   "source": [
    "The SLC groundtruth labels are very similar to the GRD labels except the addition of a 'swath\\_index' column which specifies (within a particular SLC product) what swath the groundtruth label belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68176dd-c636-47f0-af07-b27a94f6cdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_SLC.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e2a2f-21b8-48aa-8a5a-cdfe7ff4bbb4",
   "metadata": {},
   "source": [
    "Plotting the SLC groundtruth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2665f-087e-4205-922d-d1740087631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for swath_index, plot_SLC in zip([1, 2, 3], SLC_plots):\n",
    "    swath_groundtruth_SLC = groundtruth_SLC[groundtruth_SLC['swath_index'] == swath_index]\n",
    "    plot_SLC.add_bboxes(swath_groundtruth_SLC[['left', 'right', 'bottom', 'top']])\n",
    "    plot_SLC.add_labels(\n",
    "        columns = swath_groundtruth_SLC['detect_scene_column'], rows = swath_groundtruth_SLC['detect_scene_row'],\n",
    "        categories = swath_groundtruth_SLC[['detect_id', 'is_vessel', 'is_fishing', 'vessel_length_m', 'confidence']],\n",
    "        legend_label = \"groundtruth\", color = \"yellow\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f752a2-1f27-414c-927f-860d279158ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7. How to train, validate and test the reference/baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f94378e-566d-4c08-8da0-0b41c8fc6dae",
   "metadata": {},
   "source": [
    "A baseline reference implementation of a real-valued deep learning model is provided for the purpose of introducing new users to training and validating, testing models on the SARFish SLC data in addition to illustrating the use of the SARFish metrics. The reference model demonstrates how to use the SARFish metrics during training, testing and evaluation to help inform the development of better performing models.\n",
    "\n",
    "The baseline uses the predefined PyTorch implementation of FCOS; chosen because it uses the concept of “centre-ness”, which we believe is applicable to the maritime objects in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119eb4b0-2f33-43ab-a55a-9dc6e7a89f45",
   "metadata": {},
   "source": [
    "The baseline can be trained and evaluated by sequentially running the following scripts:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc6a8c-c1c5-4bdd-b4a8-6557af689713",
   "metadata": {},
   "source": [
    "1_create_tile.py generates the tiles used for training the baseline. Approximately 300GB is required for storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f1791a-f190-4db3-97b9-59901e133243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ./1_create_tile.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f198840c-d66d-409e-bddd-0d91926e93a7",
   "metadata": {},
   "source": [
    "The following trains, validates and tests the baseline model n a small subset of the SARFish dataset detailed in fold.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262edb68-4b99-4f1b-9600-a5e11305c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ./2_train.py\n",
    "# ! ./3_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd56712b-2b12-4fcf-8498-49dabe7c6d19",
   "metadata": {},
   "source": [
    "4_evaluate.py calls the SARFish_metric.py script on the testing scenes to determine model peformance on the SARFish challenge \n",
    "tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95727f-bf7e-41a0-9f33-992dcc05562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ./4_evaluate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207c2e1-6858-4743-9bd3-62b801e3fc3c",
   "metadata": {},
   "source": [
    "The following scripts call the model over the entire public partition of the SARFish dataset to generate the submission/predictions uploaded to the Kaggle competition as the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf2c31-5f2c-4148-96ce-860923551cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ./5_inference.py\n",
    "# ! ./6_concatenate_scene_predictions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8118621-aaa1-4137-94a2-2d4bc555a9cc",
   "metadata": {},
   "source": [
    "## 8. SARFish challenge prediction submission format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a6bf01-8503-427a-9f62-27668f166c4a",
   "metadata": {},
   "source": [
    "The following cell loads an simulated example of a set of predictions to illustrate the format of submissions for SLC product type in the SARFish challenge. Submissions for the challenge must have the following required columns. The predictions format (like the groundtruth labels) differs from the GRD by requiring a swath\\_index column to specify which swath the prediction belongs to. \n",
    "\n",
    "**Things to note:**\n",
    "- The Kaggle evalutation of submissions requires a dummy column named \"Index\" to work. \n",
    "- NaNs exist in the SARFish groundtruth labels where maritime object classification or length is unknown or not applicable, **however** the submission file must make a prediction for each of the columns in the submission format table to be valid. The operation of the SARFish metrics script means that maritime object classification and vessel length regression performance is only measured for detections in the submission file assigned to groundtruth for which the respective label exists.\n",
    "- Predictions/submission will be evaluated on the entire public partition of the dataset. For a participant's prediction to be evaluated, they need to provide predictions in the correct format for each scene_id in the public partition.\n",
    "- Each subsequent track is dependent on the one before it. For example: submissions to the vessel length regression track will need to first detect maritime objects, then classify vessels, and then estimate vessel length. Each Kaggle competition associated with a particular track will only evaluate that competiton's track, and same submission file may be submitted to each of the other tracks in the SARFIsh challenge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dda48e-b20f-4ead-8350-6232bccf95c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reference_SLC_predictions_path = Path(\n",
    "        \"labels\", \"reference_model\", \n",
    "        \"reference_predictions_SLC_validation_S1B_IW_SLC__1SDV_20200803T075720_20200803T075748_022756_02B2FF_E5D2.csv\"\n",
    ")\n",
    "reference_SLC_predictions = pd.read_csv(str(reference_SLC_predictions_path))\n",
    "reference_SLC_predictions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d938eb26-913b-44d6-9edc-eaf19b2ea1d8",
   "metadata": {},
   "source": [
    "Plotting the simulated SLC predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cc0f4-9341-4d07-995d-548c5941b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for swath_index, plot_SLC in zip([1, 2, 3], SLC_plots):\n",
    "    swath_reference_SLC_predictions = reference_SLC_predictions[reference_SLC_predictions['swath_index'] == swath_index]\n",
    "    plot_SLC.add_labels(\n",
    "        columns = swath_reference_SLC_predictions['detect_scene_column'], rows = swath_reference_SLC_predictions['detect_scene_row'],\n",
    "        categories = swath_reference_SLC_predictions[['is_vessel', 'is_fishing']],\n",
    "        legend_label = \"reference SLC predictions\", color = \"red\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40438c0b-29f8-49e1-8c01-56eca14f1b12",
   "metadata": {},
   "source": [
    "## 9. How to evaluate model performance using the SARFish metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6064bc3-2ade-4628-be50-e4f49907b083",
   "metadata": {},
   "source": [
    "The evaluation metrics for the SARFish is based on those from the xView3-SAR challenge. The provided SARFish\\_metrics script takes into consideration the imaging geometry differences between the GRD and SLC products and makes comparing the detection, classification, and length regression results of models trained on the two product\\_types straight-forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca0c30f-87e3-4bc9-b8ed-2bfab565f382",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 9.1 Maritime Object Detection Track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eececd7-bffc-4a4e-a4a9-e3d691dd58a2",
   "metadata": {},
   "source": [
    "The maritime object detection track is comprised of the following tasks, which are directly comparable with those from the xView3 challenge. The overall maritime object detection score is the mean of the maritime object and close-to-shore object detection tasks:\n",
    "\n",
    "$$maritime\\_object\\_detection\\_score := \\frac{(F1_D + F1_S)}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb1993-79ef-4472-9006-25351c9f0907",
   "metadata": {},
   "source": [
    "#### Maritime Object Detection Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d6c402-63c3-458c-9ebd-a1851bdffecf",
   "metadata": {},
   "source": [
    "The objective of this task is to find maritime objects in the SARFish imagery. The detection task is evaluated by assigning model predictions to the ground truth maritime object locations contained in the SARFish labels using the Hungarian matching algorithm. Model predictions within 200 meters of a 'HIGH' or 'MEDIUM' confidence ground truth are assigned as true positive detections. Successful models will have to localise maritime objects in full-size SARFish products and distinguish them from sea-clutter, small-islands and SAR ambiguities. Performance on this task is quantified over all the relevant maritime objects in the public partition using an [F1-score](https://en.wikipedia.org/wiki/F-score) denoted: \n",
    "\n",
    "$$F 1_D$$\n",
    "\n",
    "The F1 score is defined as:\n",
    "\n",
    "$$F_{1} := \\frac{2}{1/precision + 1/recall}$$\n",
    "\n",
    "where recall and precision are defined as:\n",
    "\n",
    "$$precision := \\frac{True\\_Positives}{True\\_Positives + False\\_Positives}$$\n",
    "$$recall := \\frac{True\\_Positives}{Positives}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a211453-5cd6-4203-b1fe-b6b12bd6d432",
   "metadata": {},
   "source": [
    "#### Close-to-Shore Object Detection Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e21320d-d600-4015-96cf-835318e0050d",
   "metadata": {},
   "source": [
    "The Close-to-Shore detection task is a subset of the maritime detection task. This task is evaluated by assigning model predictions to “HIGH” or “MEDIUM” confidence ground truth within 2 000 meters of the shoreline. The SARFish dataset provides two shorelines for evaluation of the Close-to-Shore task. The challenge will utilise the xView3 shoreline in order for the results to be directly comparable with the xView3 challenge. Close-to-Shore detection is a particularly challenging task whereby successful models will have to distinguish maritime objects from land objects with intense radar returns in addition to the challenges posed by standard maritime object detection. Performance on this task is quantified by the F1-score:\n",
    "\n",
    " $$F1_S$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d12d1a2-cb52-4ae3-898c-0c6f3e6467cc",
   "metadata": {},
   "source": [
    "### 9.2 Maritime Object Classification Track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a7376-1572-4e09-977c-d76330715e16",
   "metadata": {},
   "source": [
    "The maritime object classification track consists of two hierarchical classification tasks. These have also been chosen to be directly comparable with those in the xView3 challenge. The overall maritime object classification score is the mean of the vessel classification and fishing vessel classification tasks:\n",
    "\n",
    "$$Maritime\\\\_object\\\\_classification\\\\_score := \\frac{(F1_V + F1_F)}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f4edac-d34a-4696-9357-5cfa41f3ee9d",
   "metadata": {},
   "source": [
    "### Vessel Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74afe2a7-213b-4e57-a2cf-8f60d8aada9c",
   "metadata": {},
   "source": [
    "The objective of this task is: given a maritime object has been detected, distinguish whether it is a vessel or not. This task is evaluated only on the true positive predictions from the overall maritime detection task, and on ground truth detections for which a True or False “is vessel” label is available. Successful models will have to distinguish between non-vessel maritime objects such as oil-rigs and offshore wind farm turbines and vessels such as oil-tankers and container ships. Performance on this task is quantified by an [F1-score](https://en.wikipedia.org/wiki/F-score) denoted:\n",
    "\n",
    " $$F 1_V$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb1c40-2a30-4815-95c2-5e7b1bb89763",
   "metadata": {},
   "source": [
    "### Fishing Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac87a65-d83f-4f94-b18a-1ef52ba48efa",
   "metadata": {},
   "source": [
    "This task is dependent on the results of the vessel classification task. The objective of this task is: given a maritime object has been detected, and the maritime object has been correctly classified as a vessel, distinguish whether or not it is a fishing or non-fishing vessel. This task is evaluated on the true positive classifications from the vessel classification task, and only on the ground truth for which the “is vessel” label is True or False. Successful models will have to distinguish subtle differences such as those between large fishing vessels and small cargo vessels. Performance on this task is quantified by the F1-score:\n",
    "\n",
    "$$F 1_F$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761565c8-9842-4306-9994-6d77a643a6fd",
   "metadata": {},
   "source": [
    "### 9.3 Vessel Length Regression Track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b8628b-791c-4c6e-a525-f06df8a1dae3",
   "metadata": {},
   "source": [
    "The Vessel Length Regression Track is taken directly from the Percentage Error metric of the Vessel Length Estimation task of the xView3-SAR Challenge. The metric actually expresses an accuracy, but we will stick with the xView3 notation for consistency.\n",
    "\n",
    "The objective of this task is to accurately predict the length of vessels in the SARFish imagery. The task is evaluated on the true positive detections from the maritime object detection task and only on ground truth for which a vessel length label exists. We note that the correct estimation of the length of maritime objects is a crucial factor that may increase the performance of classification methods, as the length of a vessel alone is a powerful feature for the classifying different types of maritime objects. Successful models will have to overcome challenging SAR artefacts associated with high intensity radar returns from metal-hulled ships such as side-lobing, smearing and multi-path effects. Performance on this task is quantified by the aggregate percentage accuracy (erroneously called the aggregate percentage error in the xView3-SAR challenge) which penalises a prediction equally for over or underestimating vessel length. The accuracy used in this task is defined as:\n",
    "\n",
    "$$PE_L = 1 - min \\Big(\\frac{1}{N}\\frac{| min(\\hat{l}_n, l_m) \\ - \\ min(l_n, l_m) |}{min(\\hat{l}_n, l_m)}, 1\\Big)$$\n",
    "\n",
    "**Note** we still use the xView3 notation for the accuracy even though it was erroneously called an error.\n",
    "\n",
    "Where:\n",
    "predicted vessel length is:\n",
    "\n",
    "$$\\hat{l}$$\n",
    "\n",
    "actual vessel length is:\n",
    "\n",
    "$$l$$\n",
    "\n",
    "upper bound for vessel length prediction is:\n",
    "\n",
    "$$l_m$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee6d5a4-cbc6-4f0c-bc35-f5cd65bc2342",
   "metadata": {},
   "source": [
    "### 9.4 SARFish metric parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261b4aa8-951a-44a2-b7de-6b141e3aa6e2",
   "metadata": {},
   "source": [
    "#### str: shoreline\\_type [\"xView3\\_shoreline\", \"global\\_shoreline\\_vector\"] - default \"xView3\\_shoreline\"\n",
    "\n",
    "The type of shoreline vector to use for the evaluation of the close-to-shore detection task. The choices are:\n",
    "    - \"xView3\\_shoreline\" which are the xView3-SAR dataset shorelines projected into the pixel space of the GRD and SLC SARFish products. This shoreline allows a one to one comparison between the performance of models trained using the xView3-SAR imagery and SARFish imagery on the close-to-shore detection task.\n",
    "    - \"global\\_shoreline\\_vector\" derived from the [GlobalIslands global shoreline vector](https://www.tandfonline.com/doi/full/10.1080/1755876X.2018.1529714). This shoreline is an update to the shorelines using a more accurate source. [3]\n",
    "\n",
    "#### float: distance\\_from\\_shore\\_tolerance\\_meters - default: 2000.0\n",
    "\n",
    "The tolerance used to designate a prediction and groundtruth as close-to-shore. This tolerance is used to pick out a subset of the predicitions and groundtruth for evaluating the close-to-shore detection task.\n",
    "\n",
    "#### float: assignment\\_tolerance\\_meters - default: 200.0\n",
    "\n",
    "The tolerance used to threshold assignments between prediction and groundtruth detections as true positives. As a default any assignment between prediction and groundtruth under 200.0 meters distance apart is counted as a true positive for that particular detection task. This tolerance is also used in the determinination of the predictions asocciated with low confidence groundtruth if the *score\\_all* flag is False AND the *drop_\\low\\_detect* flag is True.\n",
    "\n",
    "#### float: score\\_all - default: False\n",
    "\n",
    "Whether to score the predictions against all groundtruth label confidence levels. By default the score function drops groundtruth for which the \"confidence\" attribute is \"LOW\" and evaluates model performance against \"MEDIUM\" and \"HIGH\" confidence groundtruth only.\n",
    "\n",
    "#### bool: drop\\_low\\_detect - default: True\n",
    "\n",
    "Whether to use the Hungarian matching algorithm the find the lowest distance cost assignment of predictions to the \"LOW\" confidence groundtruth and remove them from further consideration in the metrics. This option is used in concert with *score\\_all* = False, and means that when evaluating the performance of the predictions against \"MEDIUM\" and \"HIGH\" confidence groundtruth only, an unfair penalty  is not inccurred for correctly detecting maritime objects with a confidence attribute of \"LOW\".\n",
    "\n",
    "#### costly\\_dist - default: True\n",
    "\n",
    "Whether to assign a very large distance to pairwise distances between predictions and groundtruth when the distance is larger than the *assignment\\_tolerance\\_meters* threshold for true positive assignment. This modifies the optimisation problem solved by the Hungarian matching algorithm and means that predictions and groundtruth with a pairwise distances larger than the threshold are unlikely to be assigned to each other. Without this option the matching algorithm may find low cost solutions which associate more groundtruth and predictions further apart than the threshold than otherwise, and may increase the false positive and false negative count.\n",
    "\n",
    "[3] R. Sayre et al., “A new 30 meter resolution global shoreline vector and associated global islands database for the development of standardized ecological coastal units,” Journal of Operational Oceanography, vol. 12, no. sup2, pp. S47–S56, 2019. Downloaded from https://www.sciencebase.gov/catalog/item/63bdf25dd34e92aad3cda273 at https://www.sciencebase.gov/catalog/file/get/63bdf25dd34e92aad3cda273"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c237280-aca3-4412-9642-72d5007d97f0",
   "metadata": {},
   "source": [
    "### 9.5 GRD metric evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e408d4-a115-4717-9468-6b4a3a12ecd8",
   "metadata": {},
   "source": [
    "The following cell shows an example of calling the SARFish\\_metric.score function on the simulated predictions for a single scene. **Note:** the score function automatically iterates over all the scenes denoted in the 'scene\\_id' columns of the predictions csv, hence for a particular product\\_type and partition, simply include all the predictions from each of the scene\\_ids you want to evaluate. The output of the score function shows the confusion matrix and f1 score, recall, and precison summary table for the 5 metrics that comprise the xView3-SAR/SARFish aggregate metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70190fda-61df-4a5f-bf20-c31096999361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score(\n",
    "    predictions = reference_GRD_predictions, groundtruth = groundtruth_GRD, \n",
    "    xView3_SLC_GRD_correspondences = xView3_SLC_GRD_correspondences, SARFish_root_directory = SARFish_root_directory, \n",
    "    product_type = \"GRD\", shoreline_type = \"xView3_shoreline\", \n",
    "    score_all =  False, drop_low_detect = True, costly_dist = True, evaluation_mode = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba301284-40a5-48b7-8c7d-f3a73b14a3f6",
   "metadata": {},
   "source": [
    "### 9.6 SLC metric evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbddfa2a-594a-4f33-8453-e7459ed58ced",
   "metadata": {},
   "source": [
    "The evaluation of predictions on an SLC product is straight-forward. The metrics script handles the multiple swaths and imaging geometry of the SLC products. The script transforms the pixel indices into distances of meters to evaluate the detection tasks in the same units as the xView3-SAR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f726ede-fcd6-4507-a6e4-7e7e62fbd4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "score(\n",
    "    predictions = reference_SLC_predictions, groundtruth = groundtruth_SLC, \n",
    "    xView3_SLC_GRD_correspondences = xView3_SLC_GRD_correspondences, \n",
    "    SARFish_root_directory = SARFish_root_directory, product_type = \"SLC\", \n",
    "    shoreline_type = \"xView3_shoreline\", score_all =  False, drop_low_detect = True, \n",
    "    costly_dist = False, evaluation_mode = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c743cc5d-e1d2-4c25-81f0-e8a708fa90d4",
   "metadata": {},
   "source": [
    "The following cell illustrates how to run the SARFish metric script from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fcee8d-cd96-4888-a6f2-eb5879f1cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./SARFish_metric.py \\\n",
    "    -p labels/reference_model/reference_predictions_SLC_validation_S1B_IW_SLC__1SDV_20200803T075720_20200803T075748_022756_02B2FF_E5D2.csv \\\n",
    "    -g \"${SARFISH_ROOT_DIRECTORY}\"/SLC/validation/SLC_validation.csv \\\n",
    "    --sarfish_root_directory \"${SARFISH_ROOT_DIRECTORY}\" \\\n",
    "    --product_type SLC \\\n",
    "    --xview3_slc_grd_correspondences labels/xView3_SLC_GRD_correspondences.csv \\\n",
    "    --shore_type xView3_shoreline \\\n",
    "    --drop_low_detect \\\n",
    "    --no-evaluation_mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
