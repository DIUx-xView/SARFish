{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f9b654-b953-4ede-93c5-1c2f2d24172e",
   "metadata": {},
   "source": [
    "# SARFish dataset demo\n",
    "\n",
    "This jupyter notebook is designed to guide new users of the SARFish dataset. This notebook shows users how to use convenience functions included in this repo to get working with the SARFish dataset as quickly as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d6e222-ffcf-4694-bd68-b4ef253fc063",
   "metadata": {},
   "source": [
    "## What you will learn\n",
    "\n",
    "1. What the SARFish dataset is\n",
    "2. How to access the SARFish dataset\n",
    "3. Dataset structure\n",
    "4. How to load and visualise the SARFish imagery data\n",
    "5. How to load and visualise the SARFish groundtruth labels\n",
    "6. SARFish challenge prediction submission format\n",
    "7. How to evaluate model performance using the SARFish metric\n",
    "8. How to participate in the SARFish challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7319d4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/datasets/SARFish/SARFish_venv/lib64/python3.8/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/data/datasets/SARFish/SARFish_venv/lib64/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/data/datasets/SARFish/SARFish_venv/lib64/python3.8/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/data/datasets/SARFish/SARFish_venv/lib64/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "\n",
      "(python3.8:106427): dbind-WARNING **: 15:27:27.617: Couldn't register with accessibility bus: Did not receive a reply. Possible causes include: the remote application did not send a reply, the message bus security policy blocked the reply, the reply timeout expired, or the network connection was broken.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from GeoTiff import load_GeoTiff\n",
    "from visualise_labels import scale_sentinel_1_image, SARFish_Plot\n",
    "from SARFish_metric import score\n",
    "\n",
    "rng = np.random.default_rng(1234)\n",
    "\n",
    "%gui qt\n",
    "pd.set_option('display.max_columns', None)\n",
    "start = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30d602-6a9b-4ea3-9a1a-1ca674a6df6a",
   "metadata": {},
   "source": [
    "## 1. What is the SARFish dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcb2135-268d-43fb-990f-3e276d9be339",
   "metadata": {},
   "source": [
    "### 1.1 Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2452e6d1-e39d-48a3-9759-c9b896671c3c",
   "metadata": {},
   "source": [
    "SARFish is an imagery dataset for the purpose of training, validating and testing supervised machine learning models on the task of ship detection and classification. SARFish builds on the excellent work of the [xView3-SAR dataset](https://iuu.xview.us/dataset) by expanding the imagery data to include [Single Look Complex (SLC)](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar/products-algorithms/level-1-algorithms/single-look-complex) as well as [Ground Range Detected (GRD)](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-1-sar/products-algorithms/level-1-algorithms/ground-range-detected) imagery data taken directly from the European Space Agency \n",
    "(ESA) Copernicus Programme [Open Access Hub Website](https://scihub.copernicus.eu/).\n",
    "\n",
    "The following image shows a summarised description of the Sentinel-1 product family for the Interferrometric Wide (IW) mode. [^1] ![Sentinel-1 product processing pipeline summary](./images/sentinel_1_data_product_processing_levels_summary.jpg)\n",
    "\n",
    "[^1]: G. Hajduch, M. Bourbigot, H. Johnsen, and R. Piantanida, Sentinel-1 Product Specification. Sentinel-1 Mission Performance Centre, 2022, p. 34. [Online]. Available: [https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/document-library/-/asset_publisher/1dO7RF5fJMbd/content/id/4762447](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/document-library/-/asset_publisher/1dO7RF5fJMbd/content/id/4762447)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1054a6a-30f6-494b-be45-738c5d09ff14",
   "metadata": {},
   "source": [
    "### 1.2 The Sentinel-1 processing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042ed04-d71a-44e6-ad3f-a1c2b89a4515",
   "metadata": {},
   "source": [
    "The following diagram shows how the SARFish dataset extends the xView3-SAR dataset by providing the minimally pre-processed GRD and SLC counterparts to the xView3-SAR dataset imagery products and provides labels which have been re-projected labels into the pixel space of the images. ![Relationship between the xView3-SAR and SARFish datasets](./images/xView3-SAR_SARFish_dataset_relation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9867d3df-6c8c-412d-bd0a-5020e61025f5",
   "metadata": {},
   "source": [
    "### 1.3 Minimal SARFish processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07fbdb5-a067-43f9-8b0b-49af172d0f12",
   "metadata": {},
   "source": [
    "The preprocessing applied to the Sentinel-1 images to create the SARFish dataset was chosen in order to be minimally invasive. The preprocessing of the xView3-SAR dataset included radiometric calibration, decibel scaling, range doppler geocoding, projection to UTM using the [SeNtinel Application Platform (SNAP)](https://earth.esa.int/eogateway/tools/snap) [Graph Processing Tool](https://seadas.gsfc.nasa.gov/help-8.3.0/gpf/GraphProcessingTool.html). In contrast, the only operations applied to the SARFish data have been those necesary to make the images usable for computer vison tasks. The philosophy was to provide GRD and SLC data in a format as close as practicable to the Sentinel-1 data that can be downloaded from Copernicus.\n",
    "\n",
    "| Operation | xView3-SAR dataset | SARFish dataset |\n",
    "|-----------|--------------------|-----------------|\n",
    "| [radiometric-calibration](https://sentinels.copernicus.eu/web/sentinel/radiometric-calibration-of-level-1-products) | True | False |\n",
    "| [decibel scaling](https://en.wikipedia.org/wiki/Decibel) | True | False |\n",
    "| [range dopper geocoding](https://sentinel.esa.int/documents/247904/1653442/Guide-to-Sentinel-1-Geocoding.pdf)  | True | False |\n",
    "| [projection to UTM](https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system) | True | False |\n",
    "| flipping | True | True |\n",
    "| [de-bursting](https://sentinels.copernicus.eu/web/sentinel/level-1-post-processing-algorithms) | True | True |\n",
    "| [no data masking](https://gdal.org/development/rfc/rfc15_nodatabitmask.html) | True | True  |\n",
    "\n",
    "### Flipping:\n",
    "\n",
    "Flipping is applied to both GRD and SLC products. Sentinel-1 images are reflected with respect to the Earth's surface. This is due to the data aquisition method; first sensed azimuth lines are placed in the first rows in the image array. Images from both ascending and descending orbits will not map to the Earth's surface with a rotation, necessitating a flip along one axis. The images and ground control points (GCPS) are reversed along the range/x axis. \n",
    "\n",
    "### Debursting\n",
    "\n",
    "Debursting is applied only to SLC products. Sentinel-1 SLC products are provided as sets of 3 \"swaths\" per channel per scene. These swaths consist of \"sub-swaths\" or \"bursts\" which are overlapping segments of the image. The process of de-bursting is the alignment of these bursts into a contiguous image. This was done to create a one-to-one correspondence between the objects in each swath and the features on the Earth to which they correspond. It is important to note that as the deburst images are concatenations of bursts which themselves are individual SAR images, there are significant phase discontinuities on the boundaries of the bursts. It was decided for the purposes of this dataset that the bursts within the individual swaths should be merged rather than being split into seperate images.\n",
    "\n",
    "### No data masking\n",
    "\n",
    "No data masking is applied to both GRD and SLC products. Invalid pixels in the image have been masked using a nodata mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d1511-acb7-4190-ab7c-b76c07df3c86",
   "metadata": {},
   "source": [
    "## 2. Accessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9d2c8d-229f-43ca-a193-8bc643719d81",
   "metadata": {},
   "source": [
    "### 2.1 Downloading data from huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad9691-de20-4345-86e1-ea66716228e0",
   "metadata": {},
   "source": [
    "The SARFish dataset is available for download at:\n",
    "- [full SARFish dataset](https://huggingface.co/datasets/ConnorLuckettDSTG/SARFish)\n",
    "- [sample SARFish dataset](https://huggingface.co/datasets/ConnorLuckettDSTG/SARFishSample)\n",
    "\n",
    "| dataset       | coincident GRD, SLC products | compressed (GB) | uncompressed (GB) |\n",
    "| ------------- | ---------------------------- | --------------- | ----------------- |\n",
    "| SARFishSample | 1                            | 4.3             | 8.2               |\n",
    "| SARFish       | 753                          | 3293            | 6468              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62da0b15-1b17-489c-aeb8-35acf667aad3",
   "metadata": {},
   "source": [
    "#### Full SARFish dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2a7d85-52a1-475a-8dc9-8f0180c0757c",
   "metadata": {},
   "source": [
    "Make sure you have at least enough storage space for the uncompressed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953dcd98-6fb6-450e-bad5-a28f44c5daef",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd /path/to/large/storage/location\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec8d53-d447-4c3a-9ea4-b70b08111c40",
   "metadata": {},
   "source": [
    "[Create|login] to a [huggingface](https://huggingface.co) account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e5c38-589b-44a0-adc5-0aa1040baa92",
   "metadata": {},
   "source": [
    "Login to the huggingface command line interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9dc241-7e1a-4a2e-a9c1-d705f52cba91",
   "metadata": {},
   "source": [
    "```bash\n",
    "huggingface-cli login\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd0954c-21f0-484a-9c4c-e095686923f0",
   "metadata": {},
   "source": [
    "Copy the access token in settings/Access Tokens from your huggingface account. Clone the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a037cd0-845e-46a7-b9eb-97615f9d1d43",
   "metadata": {},
   "source": [
    "```bash\n",
    "git lfs install\n",
    "git clone https://huggingface.co/datasets/ConnorLuckettDSTG/SARFish\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f785c85-d6ab-42c0-acb2-40e6a841d1d7",
   "metadata": {},
   "source": [
    "#### SARFish sample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6072a4-c21a-4221-98a4-141f5cfef173",
   "metadata": {},
   "source": [
    "Substitute the final command for the full dataset with the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dd9dc1-f721-4b86-929f-462dc8665215",
   "metadata": {},
   "source": [
    "```bash\n",
    "git clone https://huggingface.co/datasets/ConnorLuckettDSTG/SARFishSample\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3ab481-ee20-4198-9513-6ba71e32cf96",
   "metadata": {},
   "source": [
    "### 2.2 Checking the md5sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a55f3f7-905e-4d79-ac6d-90b7b77cfb06",
   "metadata": {},
   "source": [
    "Use the provided sum checking functionn to check the md5 sums of the downloaded SARFish products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7460072-1a61-4b37-8f64-e943afc6edb7",
   "metadata": {},
   "source": [
    "```bash\n",
    "./check_SARFish_md5sum.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f522804-e444-4d80-9118-2a52b0d961a2",
   "metadata": {},
   "source": [
    "### 2.3 Unizipping the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ae607-4e30-455b-9855-b55b6c7a12e4",
   "metadata": {},
   "source": [
    "Use the provided unzipping function to unzip the SARFish data products in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5301422a-1ea9-422f-8419-f43972256f60",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd /path/to/SARFish/directory/GRD\n",
    "unzip\\_batch.sh -p $(find './' -type f -name \"*.SAFE.zip\")\n",
    "\n",
    "cd /path/to/SARFish/directory/SLC\n",
    "unzip\\_batch.sh -p $(find './' -type f -name \"*.SAFE.zip\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc6de6a-c07b-460c-a38b-fa49db5cd9c4",
   "metadata": {},
   "source": [
    "### 2.4 Setting the SARFish dataset root directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce3e35-3e21-4a34-9feb-b807c93a82ed",
   "metadata": {},
   "source": [
    "Modify the environment.yaml file in this directory and substitude the dummy path with the SARFish root directory. For example; if your local copy of the SARFish dataset resides in /data/SARFish, subsitute /path/to/SARFish/root/ with /data/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b8e4e-494c-42fa-894b-67d2291acfe5",
   "metadata": {},
   "source": [
    "```\n",
    "SARFISH_ROOT_DIRECTORY: /path/to/SARFish/root/ \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d95fd6d2-a24a-4393-8507-1c6876fca555",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"environment.yaml\", \"r\") as f:\n",
    "    environment = yaml.safe_load(f)\n",
    "\n",
    "SARFish_root_directory = environment['SARFish_root_directory']\n",
    "os.environ['SARFISH_ROOT_DIRECTORY'] = SARFish_root_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e4e71c-2f2e-478e-b7e5-3469d3964fe5",
   "metadata": {},
   "source": [
    "## 3. Dataset Structure\n",
    "\n",
    "The SARFish dataset is packaged in the [SAFE format](https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-1-sar/data-formats/safe-specification). The product file name consists of the unique [product identifier](https://sentinel.esa.int/documents/247904/1877131/Sentinel-1-Product-Specification) (section 3.5.1) from which the SARFish product was derived.\n",
    "\n",
    "The following tree shows an overview of the SARFish dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df47602-2d80-4d99-8eac-b0c9f853a3b0",
   "metadata": {},
   "source": [
    "```\n",
    "SARFish/\n",
    "├── GRD\n",
    "│   ├── public\n",
    "│   │   └── S1B_IW_GRDH_1SDV_*.SAFE\n",
    "│   ├── train\n",
    "│   │   └── S1B_IW_GRDH_1SDV_*.SAFE\n",
    "│   └── validation\n",
    "│       └── S1B_IW_GRDH_1SDV_*.SAFE\n",
    "└── SLC\n",
    "    ├── public\n",
    "    │   └── S1B_IW_SLC__1SDV_*.SAFE\n",
    "    ├── train\n",
    "    │   └── S1B_IW_SLC__1SDV_*.SAFE\n",
    "    └── validation\n",
    "        └── S1B_IW_SLC__1SDV_*.SAFE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fb6d4a-1b2b-4013-bf5f-58ebab456aef",
   "metadata": {},
   "source": [
    "## 3.1 Dataset Partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0665fb45-6d7c-4773-9e53-ccde33a3175b",
   "metadata": {},
   "source": [
    "The partitions of the dataset are as follows:\n",
    "\n",
    "| partition   | labels provided |\n",
    "| ----------- | --------------- |\n",
    "| train       | True            |\n",
    "| validation  | True            |\n",
    "| public      | False           |\n",
    "\n",
    "The public partition is provided with no labels. It will to be used to determine competitor's ranking in the SARFish challenge. Competitors will run their model over the public partition of the dataset producing predictions for each constituent scene and submit these in the submisson format (see section 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7550a01-bf9d-4995-a477-18a4cc1f4e4a",
   "metadata": {},
   "source": [
    "### 3.2 The two SARFish product types: GRD and SLC\n",
    "\n",
    "The SARFish dataset consists of pairs of coincident [real-valued GRD and complex valued SLC](https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-1-sar/product-types-processing-levels/level-1) imagery products from the Sentinel-1 satellite constellation. The GRD and SLC designations are the **product\\_type**. The mapping between xView3-SAR **scene\\_id** and the [Copernicus](https://www.copernicus.eu/en) product identifier is contained in the xView3\\_SLC\\_GRD\\_correspondences.csv file. The following cell shows an example of the mapping between xView3-SAR and SARFish GRD, SLC products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7218a51a-a7ce-409e-a8cb-3c6601fa0f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_id</th>\n",
       "      <th>GRD_product_identifier</th>\n",
       "      <th>SLC_product_identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>5c3d986db930f848v</td>\n",
       "      <td>S1B_IW_GRDH_1SDV_20200803T075721_20200803T0757...</td>\n",
       "      <td>S1B_IW_SLC__1SDV_20200803T075720_20200803T0757...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              scene_id                             GRD_product_identifier  \\\n",
       "703  5c3d986db930f848v  S1B_IW_GRDH_1SDV_20200803T075721_20200803T0757...   \n",
       "\n",
       "                                SLC_product_identifier  \n",
       "703  S1B_IW_SLC__1SDV_20200803T075720_20200803T0757...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xView3_SLC_GRD_correspondences = pd.read_csv(\"./labels/xView3_SLC_GRD_correspondences.csv\")\n",
    "xView3_SLC_GRD_correspondences[['scene_id', 'GRD_product_identifier', 'SLC_product_identifier']].iloc[703:704]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de840bf-6f1d-4ecd-b732-9311d7030c3b",
   "metadata": {},
   "source": [
    "The xView3\\_SLC\\_GRD\\_correspondences.csv file also contains the file names of the vh, vh imagery products and their associated annotation.xml files. This is used to pick out individual imagery data for processing and evalutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a00722e-fc13-43d3-b8dd-8cabb7c23a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 753 entries, 0 to 752\n",
      "Data columns (total 22 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   DATA_PARTITION             753 non-null    object\n",
      " 1   scene_id                   753 non-null    object\n",
      " 2   GRD_product_identifier     753 non-null    object\n",
      " 3   GRD_md5sum                 753 non-null    object\n",
      " 4   GRD_vh                     753 non-null    object\n",
      " 5   GRD_vv                     753 non-null    object\n",
      " 6   GRD_vh_annotation          753 non-null    object\n",
      " 7   GRD_vv_annotation          753 non-null    object\n",
      " 8   SLC_product_identifier     753 non-null    object\n",
      " 9   SLC_md5sum                 753 non-null    object\n",
      " 10  SLC_swath_1_vh             753 non-null    object\n",
      " 11  SLC_swath_1_vv             753 non-null    object\n",
      " 12  SLC_swath_1_vh_annotation  753 non-null    object\n",
      " 13  SLC_swath_1_vv_annotation  753 non-null    object\n",
      " 14  SLC_swath_2_vh             753 non-null    object\n",
      " 15  SLC_swath_2_vv             753 non-null    object\n",
      " 16  SLC_swath_2_vh_annotation  753 non-null    object\n",
      " 17  SLC_swath_2_vv_annotation  753 non-null    object\n",
      " 18  SLC_swath_3_vh             753 non-null    object\n",
      " 19  SLC_swath_3_vv             753 non-null    object\n",
      " 20  SLC_swath_3_vh_annotation  753 non-null    object\n",
      " 21  SLC_swath_3_vv_annotation  753 non-null    object\n",
      "dtypes: object(22)\n",
      "memory usage: 129.5+ KB\n"
     ]
    }
   ],
   "source": [
    "xView3_SLC_GRD_correspondences.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4089c6dc-5024-4fb9-9bbf-40ea7931b949",
   "metadata": {},
   "source": [
    "### 3.3 SARFish dataset format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e429a23-39c5-4047-bc73-0f17b6bba14d",
   "metadata": {},
   "source": [
    "#### GRD imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b454-fc36-4736-9d4a-23cb5ec55023",
   "metadata": {},
   "source": [
    "GRD products are uniquely identified by their:\n",
    "\n",
    "- product\\_type\n",
    "- partition \n",
    "- GRD\\_product\\_identifier\n",
    "- polarisation \n",
    "\n",
    "The tree of an example SARFish GRD Product:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450339d3-0070-4974-9c94-0aa652569187",
   "metadata": {},
   "source": [
    "```\n",
    "SARFish/GRD/validation/S1B_IW_GRDH_1SDV_20201013T054010_20201013T054035_023790_02D350_506A.SAFE/\n",
    "├── annotation\n",
    "│   └── ...\n",
    "├── manifest.safe\n",
    "├── measurement <- imagery data\n",
    "│   ├── S1B_IW_GRDH_1SDV_20201013T054010_20201013T054035_023790_02D350_506A_global_shoreline_vector.npy\n",
    "│   ├── S1B_IW_GRDH_1SDV_20201013T054010_20201013T054035_023790_02D350_506A_xView3_shoreline.npy\n",
    "│   ├── s1b-iw-grd-vh-20201013t054010-20201013t054035-023790-02d350-002_SARFish.tiff\n",
    "│   └── s1b-iw-grd-vv-20201013t054010-20201013t054035-023790-02d350-001_SARFish.tiff\n",
    "├── preview\n",
    "│   └── ...\n",
    "├── ...\n",
    "└── support\n",
    "    └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a842d6cb-6240-4376-a774-c32083b9efb1",
   "metadata": {},
   "source": [
    "The imagery data located in \"measurement\" consists of 2 images containing the polarimetic channels called VV, VH polarisations packaged in the GeoTiff format. Also included in the measurement folder are numpy archives which contain shoreline vectors which are used in the evaluation of a model's close-to-shore detection performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d453ffc5-2345-4428-bfee-bc8e07efa679",
   "metadata": {},
   "source": [
    "#### SLC imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ba2eab-9f8a-4937-9d14-bc22f3cf3cb2",
   "metadata": {},
   "source": [
    "SLC products are uniquely identified by their:\n",
    "\n",
    "- product\\_type\n",
    "- partition \n",
    "- GRD\\_product\\_identifier\n",
    "- polarisation\n",
    "- swath\\_index\n",
    "\n",
    "The tree of an example SARFish SLC Product:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b66c9d5-ea22-4ff6-93e3-b5b0ae577e22",
   "metadata": {},
   "source": [
    "```\n",
    "SARFish/SLC/validation/S1B_IW_SLC__1SDV_20201013T054008_20201013T054035_023790_02D350_04D0.SAFE\n",
    "├── annotation\n",
    "│   └── ...\n",
    "├── manifest.safe\n",
    "├── measurement\n",
    "│   ├── s1b-iw1-slc-vh-20201013t054009-20201013t054034-023790-02d350-001_SARFish.tiff                 <- swath 1 image data\n",
    "│   ├── s1b-iw1-slc-vh-20201013t054009-20201013t054034-023790-02d350-001_SARFish.tiff.msk             <- swath 1 image mask\n",
    "│   ├── s1b-iw1-slc-vv-20201013t054009-20201013t054034-023790-02d350-004_SARFish.tiff\n",
    "│   ├── s1b-iw1-slc-vv-20201013t054009-20201013t054034-023790-02d350-004_SARFish.tiff.msk\n",
    "│   ├── s1b-iw2-slc-vh-20201013t054010-20201013t054035-023790-02d350-002_SARFish.tiff\n",
    "│   ├── s1b-iw2-slc-vh-20201013t054010-20201013t054035-023790-02d350-002_SARFish.tiff.msk\n",
    "│   ├── s1b-iw2-slc-vv-20201013t054010-20201013t054035-023790-02d350-005_SARFish.tiff\n",
    "│   ├── s1b-iw2-slc-vv-20201013t054010-20201013t054035-023790-02d350-005_SARFish.tiff.msk\n",
    "│   ├── s1b-iw3-slc-vh-20201013t054008-20201013t054033-023790-02d350-003_SARFish.tiff\n",
    "│   ├── s1b-iw3-slc-vh-20201013t054008-20201013t054033-023790-02d350-003_SARFish.tiff.msk\n",
    "│   ├── s1b-iw3-slc-vv-20201013t054008-20201013t054033-023790-02d350-006_SARFish.tiff\n",
    "│   ├── s1b-iw3-slc-vv-20201013t054008-20201013t054033-023790-02d350-006_SARFish.tiff.msk\n",
    "│   ├── S1B_IW_SLC__1SDV_20201013T054008_20201013T054035_023790_02D350_04D0_1_global_shoreline_vector.npy  <- swath 1 global shoreline vector\n",
    "│   ├── S1B_IW_SLC__1SDV_20201013T054008_20201013T054035_023790_02D350_04D0_1_xView3_shoreline.npy         <- swath 1 xView3 shoreline vector\n",
    "│   ├── S1B_IW_SLC__1SDV_20201013T054008_20201013T054035_023790_02D350_04D0_2_global_shoreline_vector.npy\n",
    "│   ├── S1B_IW_SLC__1SDV_20201013T054008_20201013T054035_023790_02D350_04D0_2_xView3_shoreline.npy\n",
    "│   ├── S1B_IW_SLC__1SDV_20201013T054008_20201013T054035_023790_02D350_04D0_3_global_shoreline_vector.npy\n",
    "│   └── S1B_IW_SLC__1SDV_20201013T054008_20201013T054035_023790_02D350_04D0_3_xView3_shoreline.npy\n",
    "├── preview\n",
    "│   └── ...\n",
    "├── ...\n",
    "└── support\n",
    "    └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ea7a1-3bb1-4b44-bdd6-c0d5e77a7fc1",
   "metadata": {},
   "source": [
    "The imagery data located in the \"measurement\" directory consists of 3 sets (swaths) of 2 images containing the polarimetric channels called VV, VH packaged in the GeoTiff. Each Sentinel-1 SLC product is the composite of 3 swaths. The process of [debursting](https://github.com/senbox-org/s1tbx/blob/master/s1tbx-op-sentinel1-ui/src/main/resources/org/esa/s1tbx/sentinel1/docs/operators/TOPSARDeburstOp.html) has been applied to each swath, but the swaths have not been merged. Each SLC swath is again accompanied by a corresponding xView3-SAR and global shoreline vector. In addition corresponding [.msk](https://gdal.org/development/rfc/rfc15_nodatabitmask.html) (mask) files are used by the GeoTiff.load\\_Geotiff function in order to mask the no-data portions of the SLC products. The function load_Geotiff allow a user to easily load both GRD and SLC SARFish products taking into account their respective masks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274924db-78ad-4672-8e25-ae66e166a527",
   "metadata": {},
   "source": [
    "## 4. How to load and visualise the SARFish imagery data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2e27e5-3a7d-4fca-8bb3-298cc1441110",
   "metadata": {},
   "source": [
    "To generate the path to the GRD and SLC products associated with a single scene, we first we pick out a specific row from the xView3_SLC_GRD_correspondence table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f0aded9-a06b-4aec-bbaa-5a128759745b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATA_PARTITION                                                      validation\n",
       "scene_id                                                     5c3d986db930f848v\n",
       "GRD_product_identifier       S1B_IW_GRDH_1SDV_20200803T075721_20200803T0757...\n",
       "GRD_md5sum                                    3f8ec460304f087c8f9a59b7c0897561\n",
       "GRD_vh                       s1b-iw-grd-vh-20200803t075721-20200803t075746-...\n",
       "GRD_vv                       s1b-iw-grd-vv-20200803t075721-20200803t075746-...\n",
       "GRD_vh_annotation            s1b-iw-grd-vh-20200803t075721-20200803t075746-...\n",
       "GRD_vv_annotation            s1b-iw-grd-vv-20200803t075721-20200803t075746-...\n",
       "SLC_product_identifier       S1B_IW_SLC__1SDV_20200803T075720_20200803T0757...\n",
       "SLC_md5sum                                    c32f40b7d3a1304a30c287d7eae75684\n",
       "SLC_swath_1_vh               s1b-iw1-slc-vh-20200803t075720-20200803t075748...\n",
       "SLC_swath_1_vv               s1b-iw1-slc-vv-20200803t075720-20200803t075748...\n",
       "SLC_swath_1_vh_annotation    s1b-iw1-slc-vh-20200803t075720-20200803t075748...\n",
       "SLC_swath_1_vv_annotation    s1b-iw1-slc-vv-20200803t075720-20200803t075748...\n",
       "SLC_swath_2_vh               s1b-iw2-slc-vh-20200803t075721-20200803t075746...\n",
       "SLC_swath_2_vv               s1b-iw2-slc-vv-20200803t075721-20200803t075746...\n",
       "SLC_swath_2_vh_annotation    s1b-iw2-slc-vh-20200803t075721-20200803t075746...\n",
       "SLC_swath_2_vv_annotation    s1b-iw2-slc-vv-20200803t075721-20200803t075746...\n",
       "SLC_swath_3_vh               s1b-iw3-slc-vh-20200803t075722-20200803t075747...\n",
       "SLC_swath_3_vv               s1b-iw3-slc-vv-20200803t075722-20200803t075747...\n",
       "SLC_swath_3_vh_annotation    s1b-iw3-slc-vh-20200803t075722-20200803t075747...\n",
       "SLC_swath_3_vv_annotation    s1b-iw3-slc-vv-20200803t075722-20200803t075747...\n",
       "Name: 703, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correspondence = xView3_SLC_GRD_correspondences.iloc[703:704].squeeze()\n",
    "correspondence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13380d6-9a9e-4e81-af03-4b35915cbc77",
   "metadata": {},
   "source": [
    "### 4.1 Loading GRD imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d258040-b769-49af-be28-529bc86362ab",
   "metadata": {},
   "source": [
    "The correspondence mapping is used to generate the specific GRD product path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31d760ef-82d7-4f23-8b15-1d3c6e7e2a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/auto/SARFish/SARFish/GRD/validation/S1B_IW_GRDH_1SDV_20200803T075721_20200803T075746_022756_02B2FF_033A.SAFE/measurement/s1b-iw-grd-vh-20200803t075721-20200803t075746-022756-02b2ff-002_SARFish.tiff'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurement_path_GRD = Path(\n",
    "    SARFish_root_directory, \"GRD\", correspondence['DATA_PARTITION'], f\"{correspondence['GRD_product_identifier']}.SAFE\",\n",
    "    \"measurement\", correspondence[f'GRD_vh']\n",
    ")\n",
    "str(measurement_path_GRD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ff9b9a-7043-45ce-88ad-2a44e7d1e535",
   "metadata": {},
   "source": [
    "The image is loaded into numpy arrays using the provided GeoTiff.load_Geotiff function. The function returns an array of image data, and a second array masking the no data areas. Since the data is in linear scale, we use the provided scaling function visualise\\_labels.scale_sentinel\\_1\\_image to convert the data to a decibel scale which is more easily interpereted by humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d61de9-51c2-45d6-8e0c-4c7dd0b42752",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GRD, mask_GRD, _, _ = load_GeoTiff(str(measurement_path_GRD))\n",
    "data_scaled_GRD = scale_sentinel_1_image(data_GRD, product_type = \"GRD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e155b-b6b4-42f1-a826-0e9cf9642986",
   "metadata": {},
   "source": [
    "### 4.2 Plotting GRD imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0fcf5c-0114-4024-9b7e-11cc4cdcea46",
   "metadata": {},
   "source": [
    "The data can be plotted using the provided SARFish\\_Plot class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf417285-b1e2-4a9d-b859-653cb3d84abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_GRD = SARFish_Plot(\n",
    "    data_scaled_GRD, mask_GRD, title = f\"example plotting groundtruth labels in {correspondence[f'GRD_product_identifier']}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df89b092-513d-4593-a051-380ba8457e2c",
   "metadata": {},
   "source": [
    "### 4.3 Plotting SLC imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121abd6f-5289-45a2-ad26-821562395789",
   "metadata": {},
   "source": [
    "There are three SLC swaths per product. We will load and visualise the imagery in one cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da94872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLC swath 1 loading time: 23.21375823020935 seconds.\n",
      "SLC swath 2 loading time: 21.402974128723145 seconds.\n",
      "SLC swath 3 loading time: 23.968801975250244 seconds.\n"
     ]
    }
   ],
   "source": [
    "SLC_plots = []\n",
    "for swath_index in [1, 2, 3]:\n",
    "    start = time()\n",
    "    \n",
    "    measurement_path_SLC = Path(\n",
    "        SARFish_root_directory, \"SLC\", correspondence['DATA_PARTITION'], f\"{correspondence['SLC_product_identifier']}.SAFE\",\n",
    "        \"measurement\", correspondence[f'SLC_swath_{swath_index}_vh']\n",
    "    )\n",
    "    \n",
    "    data_SLC, mask_SLC, _, _ = load_GeoTiff(str(measurement_path_SLC))\n",
    "    data_SLC_scaled = scale_sentinel_1_image(data_SLC, product_type = \"SLC\")\n",
    "    \n",
    "    stop = time()\n",
    "    print(f\"SLC swath {swath_index} loading time: {stop - start} seconds.\")\n",
    "\n",
    "    plot_SLC = SARFish_Plot(\n",
    "        data_SLC_scaled, mask_SLC,\n",
    "        title = f\"example plotting groundtruth labels in {correspondence['SLC_product_identifier']}, swath: {swath_index}\",\n",
    "    )\n",
    "    SLC_plots.append(plot_SLC)\n",
    "    data_SLC = None\n",
    "    mask_SLC = None\n",
    "    data_scaled_SLC = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ef724-d0d0-4814-94d2-793d27e0e9a2",
   "metadata": {},
   "source": [
    "## 5. How to load and visualise the SARFish labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40d31d-05d6-43d9-aa43-7c060c97cff3",
   "metadata": {},
   "source": [
    "The groundtruth labels for the SARFish dataset are aranged similarly to the xView3-SAR dataset. The labels contain the location, classification and length of each maritime object present in all scenes for a particular product type and dataset partition. The information contained in the groundtruth labels for both the GRD and SLC products is summarised in the table below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed1e86f-4b49-40df-843a-bf66c377fd2d",
   "metadata": {},
   "source": [
    "| field     | data_type | description |\n",
    "| --------- | ----------- | --------- |\n",
    "| partition | str: \\{\"train\", \"validation\"\\} | split of the dataset |\n",
    "| product\\_type | str: \\{\"GRD\", \"SLC\"\\} | product type of the data |\n",
    "| scene\\_id | str | unique xView3 scene ID for challenge purposes |\n",
    "| detect\\_id | str | unique detection ID in format scene\\_id\\_detect\\_lat\\_detect\\_lon |\n",
    "| \\{product\\_type\\}\\_product\\_identifier | str | The copernicus Sentinel-1 product identifier for the designated product type |\n",
    "| detect\\_lat | float | latitude of detection in World Geodetic System (WGS) 84 coordinates |\n",
    "| detect\\_lon | float | longitude of detection in WGS84 coordinates |\n",
    "| detect\\_scene\\_row | int | pixel row of scene containing detection |\n",
    "| detect\\_scene\\_column | int | pixel column of scene containing detection |\n",
    "| top | float | pixel row of the top left corner of the bounding box, where available |\n",
    "| left | float | pixel column of the top left corner of the bounding box, where available |\n",
    "| bottom | float | pixel row of the bottom right corner of the bounding box, where available |\n",
    "| right | float | pixel column of the bottom right corner of the bounding box, where available |\n",
    "| vessel\\_length\\_m | float | length of vessel in meters; only provided where available from AIS |\n",
    "| source | str: \\{AIS, AIS/Manual, Manual\\} | source of detection (AIS, manual label, or both) |\n",
    "| is\\_vessel | bool | True if detection is a vessel, False otherwise |\n",
    "| is\\_fishing | bool | True if detection is a fishing vessel, False otherwise |\n",
    "| global\\_shoreline\\_vector\\_distance\\_from\\_shore\\_km | float | distance from shore of detection in kilometers as determined using the global shoreline vectors projected into the pixel space of the SARFish products  |\n",
    "| xView3\\_shoreline\\_vector\\_distance\\_from\\_shore\\_km | float | distance from shore of detection in kilometers as determined using the  xView3-SAR shoreline vectors projected into the pixel space of the SARFish products  |\n",
    "| confidence | str: \\{HIGH, MEDIUM, LOW\\} | level of confidence for is\\_vessel and is\\_fishing labels |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e376e-b887-43af-9d81-8ff6d94e4ec7",
   "metadata": {},
   "source": [
    "### 5.1 Loading and visualising GRD groundtruth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58d446e5-1377-4088-97e4-dbef01dc7398",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_GRD = pd.read_csv(\n",
    "    str(\n",
    "        Path(SARFish_root_directory, \"GRD\", correspondence['DATA_PARTITION'], f\"GRD_{correspondence['DATA_PARTITION']}.csv\")\n",
    "    )\n",
    ")\n",
    "groundtruth_GRD = groundtruth_GRD[groundtruth_GRD['GRD_product_identifier'] == correspondence['GRD_product_identifier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14419bcd-bd89-4f7a-bb09-2a2c9d607f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_GRD.add_bboxes(groundtruth_GRD[['left', 'right', 'bottom', 'top']])\n",
    "plot_GRD.add_labels(\n",
    "    columns = groundtruth_GRD['detect_scene_column'], rows = groundtruth_GRD['detect_scene_row'], \n",
    "    categories = groundtruth_GRD[['detect_id', 'is_vessel', 'is_fishing', 'vessel_length_m', 'confidence']], \n",
    "    legend_label = \"groundtruth\", color = \"yellow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce190060-0926-43ac-9d08-e00c1e01a4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 329 entries, 0 to 328\n",
      "Data columns (total 20 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   partition                                       329 non-null    object \n",
      " 1   product_type                                    329 non-null    object \n",
      " 2   scene_id                                        329 non-null    object \n",
      " 3   detect_id                                       329 non-null    object \n",
      " 4   GRD_product_identifier                          329 non-null    object \n",
      " 5   detect_lat                                      329 non-null    float64\n",
      " 6   detect_lon                                      329 non-null    float64\n",
      " 7   detect_scene_column                             329 non-null    float64\n",
      " 8   detect_scene_row                                329 non-null    float64\n",
      " 9   top                                             329 non-null    float64\n",
      " 10  left                                            329 non-null    float64\n",
      " 11  bottom                                          329 non-null    float64\n",
      " 12  right                                           329 non-null    float64\n",
      " 13  vessel_length_m                                 101 non-null    float64\n",
      " 14  source                                          329 non-null    object \n",
      " 15  is_vessel                                       329 non-null    object \n",
      " 16  is_fishing                                      40 non-null     object \n",
      " 17  global_shoreline_vector_distance_from_shore_km  329 non-null    float64\n",
      " 18  xView3_shoreline_distance_from_shore_km         329 non-null    float64\n",
      " 19  confidence                                      329 non-null    object \n",
      "dtypes: float64(11), object(9)\n",
      "memory usage: 54.0+ KB\n"
     ]
    }
   ],
   "source": [
    "groundtruth_GRD.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16244e49-b7aa-48c9-aef6-29170b9b6b8e",
   "metadata": {},
   "source": [
    "### 5.2 Loading and visualising SLC groundtruth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff2b5a11-5ea0-4f0f-881f-01fde0cc0b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth_SLC = pd.read_csv(\n",
    "    str(\n",
    "        Path(SARFish_root_directory, \"SLC\", correspondence['DATA_PARTITION'], f\"SLC_{correspondence['DATA_PARTITION']}.csv\")\n",
    "    )\n",
    ")\n",
    "groundtruth_SLC = groundtruth_SLC[groundtruth_SLC['SLC_product_identifier'] == correspondence['SLC_product_identifier']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc1bcc9-3d5c-415f-9db0-c70a0ef1b99d",
   "metadata": {},
   "source": [
    "The SLC groundtruth labels are very similar to the GRD labels except the addition of a 'swath\\_index' column which specifies (within a particular SLC product) what swath the groundtruth label belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b68176dd-c636-47f0-af07-b27a94f6cdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 321 entries, 0 to 320\n",
      "Data columns (total 21 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   partition                                       321 non-null    object \n",
      " 1   product_type                                    321 non-null    object \n",
      " 2   scene_id                                        321 non-null    object \n",
      " 3   detect_id                                       321 non-null    object \n",
      " 4   SLC_product_identifier                          321 non-null    object \n",
      " 5   swath_index                                     321 non-null    int64  \n",
      " 6   detect_lat                                      321 non-null    float64\n",
      " 7   detect_lon                                      321 non-null    float64\n",
      " 8   detect_scene_column                             321 non-null    float64\n",
      " 9   detect_scene_row                                321 non-null    float64\n",
      " 10  top                                             321 non-null    float64\n",
      " 11  left                                            321 non-null    float64\n",
      " 12  bottom                                          321 non-null    float64\n",
      " 13  right                                           321 non-null    float64\n",
      " 14  vessel_length_m                                 100 non-null    float64\n",
      " 15  source                                          321 non-null    object \n",
      " 16  is_vessel                                       321 non-null    object \n",
      " 17  is_fishing                                      41 non-null     object \n",
      " 18  global_shoreline_vector_distance_from_shore_km  321 non-null    float64\n",
      " 19  xView3_shoreline_distance_from_shore_km         321 non-null    float64\n",
      " 20  confidence                                      321 non-null    object \n",
      "dtypes: float64(11), int64(1), object(9)\n",
      "memory usage: 55.2+ KB\n"
     ]
    }
   ],
   "source": [
    "groundtruth_SLC.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e2a2f-21b8-48aa-8a5a-cdfe7ff4bbb4",
   "metadata": {},
   "source": [
    "Plotting the SLC groundtruth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ea2665f-087e-4205-922d-d1740087631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for swath_index, plot_SLC in zip([1, 2, 3], SLC_plots):\n",
    "    swath_groundtruth_SLC = groundtruth_SLC[groundtruth_SLC['swath_index'] == swath_index]\n",
    "    plot_SLC.add_bboxes(swath_groundtruth_SLC[['left', 'right', 'bottom', 'top']])\n",
    "    plot_SLC.add_labels(\n",
    "        columns = swath_groundtruth_SLC['detect_scene_column'], rows = swath_groundtruth_SLC['detect_scene_row'],\n",
    "        categories = swath_groundtruth_SLC[['detect_id', 'is_vessel', 'is_fishing', 'vessel_length_m', 'confidence']],\n",
    "        legend_label = \"groundtruth\", color = \"yellow\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aad3f3-6159-41de-9e1c-a8fc3ac1c048",
   "metadata": {},
   "source": [
    "## 6. SARFish challenge prediction submission format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe949339-9c77-4805-9318-72933e9422a7",
   "metadata": {},
   "source": [
    "### 6.1 GRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78d7d617-73c1-4695-bff1-39fda5c5a84e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Unnamed: 0              300 non-null    int64 \n",
      " 1   partition               300 non-null    object\n",
      " 2   product_type            300 non-null    object\n",
      " 3   scene_id                300 non-null    object\n",
      " 4   detect_scene_column     300 non-null    int64 \n",
      " 5   detect_scene_row        300 non-null    int64 \n",
      " 6   vessel_length_m         300 non-null    int64 \n",
      " 7   is_vessel               300 non-null    bool  \n",
      " 8   is_fishing              300 non-null    bool  \n",
      " 9   GRD_product_identifier  300 non-null    object\n",
      "dtypes: bool(2), int64(4), object(4)\n",
      "memory usage: 19.5+ KB\n"
     ]
    }
   ],
   "source": [
    "reference_GRD_predictions = pd.read_csv(str(Path(\"./labels/reference_GRD_predictions.csv\")))\n",
    "reference_GRD_predictions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce786c-0459-43c0-aef1-97bbd4c4922b",
   "metadata": {},
   "source": [
    "The plotted simulated GRD predictions. Use your mouse to click on individual labels within the plot to see more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dfafc47-74e1-46bf-9448-a3705e0a6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_GRD.add_labels(\n",
    "    columns = reference_GRD_predictions['detect_scene_column'], rows = reference_GRD_predictions['detect_scene_row'], \n",
    "    categories = reference_GRD_predictions[['is_vessel', 'is_fishing', 'vessel_length_m']], \n",
    "    legend_label = \"reference GRD predictions\", color = \"red\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7fd328-61a9-414e-8f0f-91afa635fa6d",
   "metadata": {},
   "source": [
    "### 6.2 SLC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a5493-6287-4233-915f-e01fe2b41551",
   "metadata": {},
   "source": [
    "The following cell loads an simulated example of a set of predictions to illustrate the format of submissions for SLC product type in the SARFish challenge. Submissions for the challenge must have the following required columns. The predictions format (like the groundtruth labels) differs from the GRD by requiring a swath\\_index column to specify which swath the prediction belongs to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6dda48e-b20f-4ead-8350-6232bccf95c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600 entries, 0 to 599\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Unnamed: 0              600 non-null    int64 \n",
      " 1   partition               600 non-null    object\n",
      " 2   product_type            600 non-null    object\n",
      " 3   scene_id                600 non-null    object\n",
      " 4   detect_scene_column     600 non-null    int64 \n",
      " 5   detect_scene_row        600 non-null    int64 \n",
      " 6   vessel_length_m         600 non-null    int64 \n",
      " 7   is_vessel               600 non-null    bool  \n",
      " 8   is_fishing              600 non-null    bool  \n",
      " 9   SLC_product_identifier  600 non-null    object\n",
      " 10  swath_index             600 non-null    int64 \n",
      "dtypes: bool(2), int64(5), object(4)\n",
      "memory usage: 43.5+ KB\n"
     ]
    }
   ],
   "source": [
    "reference_SLC_predictions = pd.read_csv(str(Path(\"./labels/reference_SLC_predictions.csv\")))\n",
    "reference_SLC_predictions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75958ea-27b8-4a0e-b779-7afd347d9697",
   "metadata": {},
   "source": [
    "Plotting the simulated SLC predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b505469b-c5e1-4a8c-b245-2d322a11fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for swath_index, plot_SLC in zip([1, 2, 3], SLC_plots):\n",
    "    swath_reference_SLC_predictions = reference_SLC_predictions[reference_SLC_predictions['swath_index'] == swath_index]\n",
    "    plot_SLC.add_labels(\n",
    "        columns = swath_reference_SLC_predictions['detect_scene_column'], rows = swath_reference_SLC_predictions['detect_scene_row'],\n",
    "        categories = swath_reference_SLC_predictions[['is_vessel', 'is_fishing', 'vessel_length_m']],\n",
    "        legend_label = \"reference SLC predictions\", color = \"red\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871678eb-c91f-4930-b8de-9f4ba380b699",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6.3 SARFish reference example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b756d9-0e84-4b3d-8868-c66b855c0add",
   "metadata": {},
   "source": [
    "Provided in refence/SARFish_reference.py is a simple didactic example of an algorithm which produces predictions. This is to be used as a basic staring point showing the conceptual layout of a training and inference script. \n",
    "\n",
    "# UPDATE for deep learning reference model\n",
    "\n",
    "The following cell runs the SARFish reference algorithm on the command line to generate the predictions for the GRD and SLC product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b66b913-8b79-4d31-bb98-8dcc26dd8b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ./SARFish_reference.py --sarfish_root_directory \"${SARFISH_ROOT_DIRECTORY}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40438c0b-29f8-49e1-8c01-56eca14f1b12",
   "metadata": {},
   "source": [
    "## 7. How to evaluate model performance using the SARFish metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6064bc3-2ade-4628-be50-e4f49907b083",
   "metadata": {},
   "source": [
    "The evaluation metrics for the SARFish dataset is the same the xView3-SAR challenge. The provided SARFish\\_metrics script takes into consideration the imaging geometry differences between the GRD and SLC products and makes comparing the detection, classification, and length regression results of models trained on the two product\\_types straight-forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684c95c5-be2f-4c8d-9ff8-245e6efe2196",
   "metadata": {},
   "source": [
    "### 7.1 SARFish metric tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed16b4-de88-4e5f-bffc-af34c1595f48",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Aggregate score\n",
    "\n",
    "The aggregate overall score is calculated using a linear combination of the F1 scores from the 5 following tasks. It is a scalar that sums up the performance for direct comparison on a leaderboard. \n",
    "\n",
    "$$ M_R = F1_D * \\frac{1 + F1_S  + F1_V + F1_F + PE_L}{5} $$\n",
    "\n",
    "$$ PE_{L} = 1 - \\frac{1}{N} \\sum_{n=1}^{N} \\frac{| \\hat{\\ell} - \\ell|}{\\ell}. $$\n",
    "\n",
    "More information about the definitions of the metrics used can be found in the [xView3-SAR paper](https://arxiv.org/abs/2206.00897) [2]\n",
    "\n",
    "#### 1. Maritime object detection task ($F1_D$)\n",
    "\n",
    "The detection task is measured by assigning the predictions to the groundtruth maritime object locations using the Hungarian matching algorithm. The assignments determined by the algorithm are affected by the *assignment\\_tolerance\\_meters* and *costly\\_dist* flag. The subset of groundtruth and prediction labels used in the evalutation of this task is determined by the *score\\_all* and *drop\\_low\\_detect* flags. Due to the dependence of the following tasks on the output of the detection task, the implications of the choice of the parameters relevant to this task will propagate through the scores.\n",
    "\n",
    "#### 2. close-to-shore subset detection task ($F1_S$)\n",
    "\n",
    "The close-to-shore detection task is measured by assigning the predictions to groundtruth maritime object locations given the *distance\\_from\\_shore\\_tolerance\\_meters* threshold. The task of correctly detecting maritime objects in the close-to-shore environment is a harder than in open sea. The definition of close to shore is determined by both the *distance\\_from\\_shore\\_tolerance\\_meters* threshold and the *shoreline\\_type* used.\n",
    "\n",
    "#### 3. 'is vessel' classification task ($F1_V$)\n",
    "\n",
    "The boolean 'is\\_vessel' classification task is measured on the predictions and groundtruth that were determined to be true positives from the detection task. Only the true postives for which the groundtruth label's 'is\\_vessel' category is True or False are evaluated; NaN values are discarded. Each detection task true postive prediction and groundtruth pair is assigned as a true positive, false positive, false negative and true negative for the 'is\\_vessel' task. \n",
    "\n",
    "#### 4. 'is fishing' classification task ($F1_F$)\n",
    "\n",
    "The boolean fishing vessel classification task is dependent on the true positive prediction and groundtruth pairs from the 'is\\_vessel' classification task. Differing from the evaluation of the 'is\\_vessel' classification, only true positive pairs for which the 'is\\_vessel' label is True are evaluated. This has the implication of restricting the evaluation of the 'is\\_fishing' task in a way that respects the hierarchical nature of the classification of fishing vessels as a subset of vessels. Again NaN values are discarded. \n",
    "\n",
    "#### 5. vessel length regression task ($PE_L$)\n",
    "\n",
    "The length regression task is measured on the true positive predictions and groundtruth determined by the detection task. The subset to evaluate is further restricted to just the true positive prediction and groundtruth pairs for which the groundtruth 'vessel\\_length\\_m' attribute is given. Again NaN values are discarded. \n",
    "\n",
    "Change from xView3-SAR:\n",
    "\n",
    "Previously in the metrics of the xView3-SAR challenge, the relative error was calculated with respect to the groundtruth 'vessel\\_length\\_m' attribute. The implication is that relative errors could be larger than 1. Subsequently the relative error is subtracted from 1 to get the mean relative accuracy. If the mean relative error is greater than 1, a length regression task accuracy of 0 is returned.\n",
    "\n",
    "In this implementation, the relative error is calculated with respect to the max(groundtruth\\['vessel\\_length\\_m'\\], predictions\\['vessel\\_length\\_m'\\]). This ensures that the relative error is at maximum 1. The implication is that the SARFish length regression performance metric is not as harsh as the xView3-SAR version. \n",
    "\n",
    "[2] F. Paolo et al., xView3-SAR: Detecting Dark Fishing Activity Using Synthetic Aperture Radar Imagery. arXiv, 2022. doi: 10.48550/ARXIV.2206.00897. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee6d5a4-cbc6-4f0c-bc35-f5cd65bc2342",
   "metadata": {},
   "source": [
    "### 7.2 SARFish metric parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261b4aa8-951a-44a2-b7de-6b141e3aa6e2",
   "metadata": {},
   "source": [
    "#### str: shoreline\\_type [\"xView3\\_shoreline\", \"global\\_shoreline\\_vector\"] - default \"xView3\\_shoreline\"\n",
    "\n",
    "The type of shoreline vector to use for the evaluation of the close-to-shore detection task. The choices are:\n",
    "    - \"xView3\\_shoreline\" which are the xView3-SAR dataset shorelines projected into the pixel space of the GRD and SLC SARFish products. This shoreline allows a one to one comparison between the performance of models trained using the xView3-SAR imagery and SARFish imagery on the close-to-shore detection task.\n",
    "    - \"global\\_shoreline\\_vector\" derived from the [GlobalIslands global shoreline vector](https://www.tandfonline.com/doi/full/10.1080/1755876X.2018.1529714). This shoreline is an update to the shorelines using a more accurate source. [3]\n",
    "\n",
    "#### float: distance\\_from\\_shore\\_tolerance\\_meters - default: 2000.0\n",
    "\n",
    "The tolerance used to designate a prediction and groundtruth as close-to-shore. This tolerance is used to pick out a subset of the predicitions and groundtruth for evaluating the close-to-shore detection task.\n",
    "\n",
    "#### float: assignment\\_tolerance\\_meters - default: 200.0\n",
    "\n",
    "The tolerance used to threshold assignments between prediction and groundtruth detections as true positives. As a default any assignment between prediction and groundtruth under 200.0 meters distance apart is counted as a true positive for that particular detection task. This tolerance is also used in the determinination of the predictions asocciated with low confidence groundtruth if the *score\\_all* flag is False AND the *drop_\\low\\_detect* flag is True.\n",
    "\n",
    "#### float: score\\_all - default: False\n",
    "\n",
    "Whether to score the predictions against all groundtruth label confidence levels. By default the score function drops groundtruth for which the \"confidence\" attribute is \"LOW\" and evaluates model performance against \"MEDIUM\" and \"HIGH\" confidence groundtruth only.\n",
    "\n",
    "#### bool: drop\\_low\\_detect - default: True\n",
    "\n",
    "Whether to use the Hungarian matching algorithm the find the lowest distance cost assignment of predictions to the \"LOW\" confidence groundtruth and remove them from further consideration in the metrics. This option is used in concert with *score\\_all* = False, and means that when evaluating the performance of the predictions against \"MEDIUM\" and \"HIGH\" confidence groundtruth only, an unfair penalty  is not inccurred for correctly detecting maritime objects with a confidence attribute of \"LOW\".\n",
    "\n",
    "#### costly\\_dist - default: True\n",
    "\n",
    "Whether to assign a very large distance to pairwise distances between predictions and groundtruth when the distance is larger than the *assignment\\_tolerance\\_meters* threshold for true positive assignment. This modifies the optimisation problem solved by the Hungarian matching algorithm and means that predictions and groundtruth with a pairwise distances larger than the threshold are unlikely to be assigned to each other. Without this option the matching algorithm may find low cost solutions which associate more groundtruth and predictions further apart than the threshold than otherwise, and may increase the false positive and false negative count.\n",
    "\n",
    "[3] R. Sayre et al., “A new 30 meter resolution global shoreline vector and associated global islands database for the development of standardized ecological coastal units,” Journal of Operational Oceanography, vol. 12, no. sup2, pp. S47–S56, 2019. Downloaded from https://www.sciencebase.gov/catalog/item/63bdf25dd34e92aad3cda273 at https://www.sciencebase.gov/catalog/file/get/63bdf25dd34e92aad3cda273"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c237280-aca3-4412-9642-72d5007d97f0",
   "metadata": {},
   "source": [
    "### 7.3 GRD metric evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e408d4-a115-4717-9468-6b4a3a12ecd8",
   "metadata": {},
   "source": [
    "The following cell shows an example of calling the SARFish\\_metric.score function on the simulated predictions for a single scene. **Note:** the score function automatically iterates over all the scenes denoted in the 'scene\\_id' columns of the predictions csv, hence for a particular product\\_type and partition, simply include all the predictions from each of the scene\\_ids you want to evaluate. The output of the score function shows the confusion matrix and f1 score, recall, and precison summary table for the 5 metrics that comprise the xView3-SAR/SARFish aggregate metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70190fda-61df-4a5f-bf20-c31096999361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoreline_type:     xView3_shoreline\n",
      "score_all:          False\n",
      "drop_low_detect:    True\n",
      "costly_dist:        True\n",
      "evaluation_mode:    False\n",
      "\n",
      "dropping predictions corresponding to low confidence groundtruth...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae90c05c5d43484092ff6b1d53555e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluating S1B_IW_GRDH_1SDV_20200803T075721_20200803T075746_022756_02B2FF_033A\n",
      "\u001b[1;93m\n",
      "location \u001b[0mtask confusion matrix:\n",
      "                      ╔═══════════════════╗\n",
      "                      ║    groundtruth    ║\n",
      "                      ╠═════════╤═════════╣\n",
      "                      ║ True    │ False   ║\n",
      "╔═════════════╦═══════╬═════════╪═════════╣\n",
      "║ predictions ║ True  ║ tp:  29 │ fp: 262 ║\n",
      "║             ╟───────╫─────────┼─────────╢\n",
      "║             ║ False ║ fn: 188 │ tn: N/A ║\n",
      "╚═════════════╩═══════╩═════════╧═════════╝\n",
      "\u001b[1;93m\n",
      "location \u001b[0mtask performance:\n",
      "╔═══════════╤════════════════════╗\n",
      "║\u001b[1;94m precision \u001b[0m│ 0.0996563573883162 ║\n",
      "║\u001b[1;31m recall    \u001b[0m│ 0.1336405529953917 ║\n",
      "║\u001b[1;35m F1 score  \u001b[0m│ 0.1141732283464567 ║\n",
      "╚═══════════╧════════════════════╝\n",
      "\u001b[1;93m\n",
      "location_close_to_shore \u001b[0mtask confusion matrix:\n",
      "                      ╔═══════════════════╗\n",
      "                      ║    groundtruth    ║\n",
      "                      ╠═════════╤═════════╣\n",
      "                      ║ True    │ False   ║\n",
      "╔═════════════╦═══════╬═════════╪═════════╣\n",
      "║ predictions ║ True  ║ tp:  22 │ fp: 121 ║\n",
      "║             ╟───────╫─────────┼─────────╢\n",
      "║             ║ False ║ fn: 136 │ tn: N/A ║\n",
      "╚═════════════╩═══════╩═════════╧═════════╝\n",
      "\u001b[1;93m\n",
      "location close to shore \u001b[0mtask performance:\n",
      "╔═══════════╤════════════════════╗\n",
      "║\u001b[1;94m precision \u001b[0m│ 0.1538461538461539 ║\n",
      "║\u001b[1;31m recall    \u001b[0m│ 0.1392405063291139 ║\n",
      "║\u001b[1;35m F1 score  \u001b[0m│ 0.1461794019933555 ║\n",
      "╚═══════════╧════════════════════╝\n",
      "\u001b[1;93m\n",
      "is_vessel \u001b[0mtask confusion matrix:\n",
      "                      ╔═════════════════╗\n",
      "                      ║   groundtruth   ║\n",
      "                      ╠════════╤════════╣\n",
      "                      ║ True   │ False  ║\n",
      "╔═════════════╦═══════╬════════╪════════╣\n",
      "║ predictions ║ True  ║ tp: 13 │ fp:  5 ║\n",
      "║             ╟───────╫────────┼────────╢\n",
      "║             ║ False ║ fn:  9 │ tn:  2 ║\n",
      "╚═════════════╩═══════╩════════╧════════╝\n",
      "\u001b[1;93m\n",
      "is_vessel \u001b[0mtask performance:\n",
      "╔═══════════╤════════════════════╗\n",
      "║\u001b[1;94m precision \u001b[0m│ 0.7222222222222222 ║\n",
      "║\u001b[1;31m recall    \u001b[0m│ 0.5909090909090909 ║\n",
      "║\u001b[1;35m F1 score  \u001b[0m│ 0.6500000000000000 ║\n",
      "╚═══════════╧════════════════════╝\n",
      "\u001b[1;93m\n",
      "is_fishing \u001b[0mtask confusion matrix:\n",
      "                      ╔═══════════════╗\n",
      "                      ║  groundtruth  ║\n",
      "                      ╠═══════╤═══════╣\n",
      "                      ║ True  │ False ║\n",
      "╔═════════════╦═══════╬═══════╪═══════╣\n",
      "║ predictions ║ True  ║ tp: 1 │ fp: 1 ║\n",
      "║             ╟───────╫───────┼───────╢\n",
      "║             ║ False ║ fn: 0 │ tn: 2 ║\n",
      "╚═════════════╩═══════╩═══════╧═══════╝\n",
      "\u001b[1;93m\n",
      "is_fishing \u001b[0mtask performance:\n",
      "╔═══════════╤════════════════════╗\n",
      "║\u001b[1;94m precision \u001b[0m│ 0.5000000000000000 ║\n",
      "║\u001b[1;31m recall    \u001b[0m│ 1.0000000000000000 ║\n",
      "║\u001b[1;35m F1 score  \u001b[0m│ 0.6666666666666666 ║\n",
      "╚═══════════╧════════════════════╝\n",
      "\u001b[1;93m\n",
      "length regression \u001b[0mtask performance:\n",
      "╔══════════╤════════════════════╗\n",
      "║\u001b[1;32m accuracy \u001b[0m│ 0.0000000000000000 ║\n",
      "╚══════════╧════════════════════╝\n",
      "\u001b[1;93m\n",
      "aggregate \u001b[0mtask performance:\n",
      "╔═══════╤════════════════════╗\n",
      "║\u001b[1;36m score \u001b[0m│ 0.0555073676814020 ║\n",
      "╚═══════╧════════════════════╝\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loc_fscore': 0.1141732283464567,\n",
       " 'loc_fscore_shore': 0.1461794019933555,\n",
       " 'vessel_fscore': 0.65,\n",
       " 'fishing_fscore': 0.6666666666666666,\n",
       " 'length_acc': 0.0,\n",
       " 'aggregate': 0.05550736768140202}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(\n",
    "    predictions = reference_GRD_predictions, groundtruth = groundtruth_GRD, \n",
    "    xView3_SLC_GRD_correspondences = xView3_SLC_GRD_correspondences, SARFish_root_directory = SARFish_root_directory, \n",
    "    product_type = \"GRD\", shoreline_type = \"xView3_shoreline\", \n",
    "    score_all =  False, drop_low_detect = True, costly_dist = True, evaluation_mode = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c743cc5d-e1d2-4c25-81f0-e8a708fa90d4",
   "metadata": {},
   "source": [
    "The following cell illustrates how to run the SARFish metric script from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c8e805e-5e6b-40bc-8cfc-90ea88a11778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoreline_type:     xView3_shoreline\n",
      "score_all:          False\n",
      "drop_low_detect:    True\n",
      "costly_dist:        True\n",
      "evaluation_mode:    False\n",
      "\n",
      "dropping predictions corresponding to low confidence groundtruth...\n",
      "1it [00:00, 51.09it/s]\n",
      "\n",
      "evaluating S1B_IW_GRDH_1SDV_20200803T075721_20200803T075746_022756_02B2FF_033A\n",
      "\u001b[1;93m\n",
      "location \u001b[0mtask confusion matrix:\n",
      "                      ╔═══════════════════╗\n",
      "                      ║    groundtruth    ║\n",
      "                      ╠═════════╤═════════╣\n",
      "                      ║ True    │ False   ║\n",
      "╔═════════════╦═══════╬═════════╪═════════╣\n",
      "║ predictions ║ True  ║ tp:  29 │ fp: 262 ║\n",
      "║             ╟───────╫─────────┼─────────╢\n",
      "║             ║ False ║ fn: 188 │ tn: N/A ║\n",
      "╚═════════════╩═══════╩═════════╧═════════╝\n",
      "\u001b[1;93m\n",
      "location \u001b[0mtask performance:\n",
      "╔═══════════╤════════════════════╗\n",
      "║\u001b[1;94m precision \u001b[0m│ 0.0996563573883162 ║\n",
      "║\u001b[1;31m recall    \u001b[0m│ 0.1336405529953917 ║\n",
      "║\u001b[1;35m F1 score  \u001b[0m│ 0.1141732283464567 ║\n",
      "╚═══════════╧════════════════════╝\n",
      "\u001b[1;93m\n",
      "location_close_to_shore \u001b[0mtask confusion matrix:\n",
      "                      ╔═══════════════════╗\n",
      "                      ║    groundtruth    ║\n",
      "                      ╠═════════╤═════════╣\n",
      "                      ║ True    │ False   ║\n",
      "╔═════════════╦═══════╬═════════╪═════════╣\n",
      "║ predictions ║ True  ║ tp:  22 │ fp: 121 ║\n",
      "║             ╟───────╫─────────┼─────────╢\n",
      "║             ║ False ║ fn: 136 │ tn: N/A ║\n",
      "╚═════════════╩═══════╩═════════╧═════════╝\n",
      "\u001b[1;93m\n",
      "location close to shore \u001b[0mtask performance:\n",
      "╔═══════════╤════════════════════╗\n",
      "║\u001b[1;94m precision \u001b[0m│ 0.1538461538461539 ║\n",
      "║\u001b[1;31m recall    \u001b[0m│ 0.1392405063291139 ║\n",
      "║\u001b[1;35m F1 score  \u001b[0m│ 0.1461794019933555 ║\n",
      "╚═══════════╧════════════════════╝\n",
      "\u001b[1;93m\n",
      "is_vessel \u001b[0mtask confusion matrix:\n",
      "                      ╔═════════════════╗\n",
      "                      ║   groundtruth   ║\n",
      "                      ╠════════╤════════╣\n",
      "                      ║ True   │ False  ║\n",
      "╔═════════════╦═══════╬════════╪════════╣\n",
      "║ predictions ║ True  ║ tp: 13 │ fp:  5 ║\n",
      "║             ╟───────╫────────┼────────╢\n",
      "║             ║ False ║ fn:  9 │ tn:  2 ║\n",
      "╚═════════════╩═══════╩════════╧════════╝\n",
      "\u001b[1;93m\n",
      "is_vessel \u001b[0mtask performance:\n",
      "╔═══════════╤════════════════════╗\n",
      "║\u001b[1;94m precision \u001b[0m│ 0.7222222222222222 ║\n",
      "║\u001b[1;31m recall    \u001b[0m│ 0.5909090909090909 ║\n",
      "║\u001b[1;35m F1 score  \u001b[0m│ 0.6500000000000000 ║\n",
      "╚═══════════╧════════════════════╝\n",
      "\u001b[1;93m\n",
      "is_fishing \u001b[0mtask confusion matrix:\n",
      "                      ╔═══════════════╗\n",
      "                      ║  groundtruth  ║\n",
      "                      ╠═══════╤═══════╣\n",
      "                      ║ True  │ False ║\n",
      "╔═════════════╦═══════╬═══════╪═══════╣\n",
      "║ predictions ║ True  ║ tp: 1 │ fp: 1 ║\n",
      "║             ╟───────╫───────┼───────╢\n",
      "║             ║ False ║ fn: 0 │ tn: 2 ║\n",
      "╚═════════════╩═══════╩═══════╧═══════╝\n",
      "\u001b[1;93m\n",
      "is_fishing \u001b[0mtask performance:\n",
      "╔═══════════╤════════════════════╗\n",
      "║\u001b[1;94m precision \u001b[0m│ 0.5000000000000000 ║\n",
      "║\u001b[1;31m recall    \u001b[0m│ 1.0000000000000000 ║\n",
      "║\u001b[1;35m F1 score  \u001b[0m│ 0.6666666666666666 ║\n",
      "╚═══════════╧════════════════════╝\n",
      "\u001b[1;93m\n",
      "length regression \u001b[0mtask performance:\n",
      "╔══════════╤════════════════════╗\n",
      "║\u001b[1;32m accuracy \u001b[0m│ 0.0000000000000000 ║\n",
      "╚══════════╧════════════════════╝\n",
      "\u001b[1;93m\n",
      "aggregate \u001b[0mtask performance:\n",
      "╔═══════╤════════════════════╗\n",
      "║\u001b[1;36m score \u001b[0m│ 0.0555073676814020 ║\n",
      "╚═══════╧════════════════════╝\n",
      "\n",
      "loc_fscore:       0.1141732283464567\n",
      "loc_fscore_shore: 0.1461794019933555\n",
      "vessel_fscore:    0.65\n",
      "fishing_fscore:   0.6666666666666666\n",
      "length_acc:       0.0\n",
      "aggregate:        0.05550736768140202\n"
     ]
    }
   ],
   "source": [
    "! ./SARFish_metric.py \\\n",
    "    -p ./labels/reference_GRD_predictions.csv \\\n",
    "    -g \"${SARFISH_ROOT_DIRECTORY}\"/GRD/validation/GRD_validation.csv \\\n",
    "    --sarfish_root_directory \"${SARFISH_ROOT_DIRECTORY}\"\\\n",
    "    --product_type GRD \\\n",
    "    --xview3_slc_grd_correspondences ./labels/xView3_SLC_GRD_correspondences.csv \\\n",
    "    --shore_type xView3_shoreline \\\n",
    "    --drop_low_detect \\\n",
    "    --costly_dist \\\n",
    "    --no-evaluation_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba301284-40a5-48b7-8c7d-f3a73b14a3f6",
   "metadata": {},
   "source": [
    "### 7.4 SLC metric evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbddfa2a-594a-4f33-8453-e7459ed58ced",
   "metadata": {},
   "source": [
    "The evaluation of predictions on an SLC product is straight-forward. The metrics script handles the multiple swaths and imaging geometry of the SLC products. The script transforms the pixel indices into distances of meters to evaluate the detection tasks in the same units as the xView3-SAR data (in its metric script), or the SARFish GRD products shown in the cells above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f726ede-fcd6-4507-a6e4-7e7e62fbd4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoreline_type:     xView3_shoreline\n",
      "score_all:          False\n",
      "drop_low_detect:    True\n",
      "costly_dist:        True\n",
      "evaluation_mode:    False\n",
      "\n",
      "dropping predictions corresponding to low confidence groundtruth...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5767162d2241469fcd88af7796a5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluating S1B_IW_SLC__1SDV_20200803T075720_20200803T075748_022756_02B2FF_E5D2\n",
      "\u001b[1;93m\n",
      "location \u001b[0mtask confusion matrix:\n",
      "                      ╔═══════════════════╗\n",
      "                      ║    groundtruth    ║\n",
      "                      ╠═════════╤═════════╣\n",
      "                      ║ True    │ False   ║\n",
      "╔═════════════╦═══════╬═════════╪═════════╣\n",
      "║ predictions ║ True  ║ tp:  25 │ fp: 565 ║\n",
      "║             ╟───────╫─────────┼─────────╢\n",
      "║             ║ False ║ fn: 190 │ tn: N/A ║\n",
      "╚═════════════╩═══════╩═════════╧═════════╝\n",
      "\u001b[1;93m\n",
      "location \u001b[0mtask performance:\n",
      "╔═══════════╤════════════════════╗\n",
      "║\u001b[1;94m precision \u001b[0m│ 0.0423728813559322 ║\n",
      "║\u001b[1;31m recall    \u001b[0m│ 0.1162790697674419 ║\n",
      "║\u001b[1;35m F1 score  \u001b[0m│ 0.0621118012422360 ║\n",
      "╚═══════════╧════════════════════╝\n",
      "\u001b[1;93m\n",
      "location_close_to_shore \u001b[0mtask confusion matrix:\n",
      "                      ╔═══════════════════╗\n",
      "                      ║    groundtruth    ║\n",
      "                      ╠═════════╤═════════╣\n",
      "                      ║ True    │ False   ║\n",
      "╔═════════════╦═══════╬═════════╪═════════╣\n",
      "║ predictions ║ True  ║ tp:  20 │ fp: 273 ║\n",
      "║             ╟───────╫─────────┼─────────╢\n",
      "║             ║ False ║ fn: 136 │ tn: N/A ║\n",
      "╚═════════════╩═══════╩═════════╧═════════╝\n",
      "\u001b[1;93m\n",
      "location close to shore \u001b[0mtask performance:\n",
      "╔═══════════╤════════════════════╗\n",
      "║\u001b[1;94m precision \u001b[0m│ 0.0682593856655290 ║\n",
      "║\u001b[1;31m recall    \u001b[0m│ 0.1282051282051282 ║\n",
      "║\u001b[1;35m F1 score  \u001b[0m│ 0.0890868596881960 ║\n",
      "╚═══════════╧════════════════════╝\n",
      "\u001b[1;93m\n",
      "is_vessel \u001b[0mtask confusion matrix:\n",
      "                      ╔═════════════════╗\n",
      "                      ║   groundtruth   ║\n",
      "                      ╠════════╤════════╣\n",
      "                      ║ True   │ False  ║\n",
      "╔═════════════╦═══════╬════════╪════════╣\n",
      "║ predictions ║ True  ║ tp: 17 │ fp:  2 ║\n",
      "║             ╟───────╫────────┼────────╢\n",
      "║             ║ False ║ fn:  5 │ tn:  1 ║\n",
      "╚═════════════╩═══════╩════════╧════════╝\n",
      "\u001b[1;93m\n",
      "is_vessel \u001b[0mtask performance:\n",
      "╔═══════════╤════════════════════╗\n",
      "║\u001b[1;94m precision \u001b[0m│ 0.8947368421052632 ║\n",
      "║\u001b[1;31m recall    \u001b[0m│ 0.7727272727272727 ║\n",
      "║\u001b[1;35m F1 score  \u001b[0m│ 0.8292682926829269 ║\n",
      "╚═══════════╧════════════════════╝\n",
      "\u001b[1;93m\n",
      "is_fishing \u001b[0mtask confusion matrix:\n",
      "                      ╔═══════════════╗\n",
      "                      ║  groundtruth  ║\n",
      "                      ╠═══════╤═══════╣\n",
      "                      ║ True  │ False ║\n",
      "╔═════════════╦═══════╬═══════╪═══════╣\n",
      "║ predictions ║ True  ║ tp: 1 │ fp: 1 ║\n",
      "║             ╟───────╫───────┼───────╢\n",
      "║             ║ False ║ fn: 1 │ tn: 1 ║\n",
      "╚═════════════╩═══════╩═══════╧═══════╝\n",
      "\u001b[1;93m\n",
      "is_fishing \u001b[0mtask performance:\n",
      "╔═══════════╤════════════════════╗\n",
      "║\u001b[1;94m precision \u001b[0m│ 0.5000000000000000 ║\n",
      "║\u001b[1;31m recall    \u001b[0m│ 0.5000000000000000 ║\n",
      "║\u001b[1;35m F1 score  \u001b[0m│ 0.5000000000000000 ║\n",
      "╚═══════════╧════════════════════╝\n",
      "\u001b[1;93m\n",
      "length regression \u001b[0mtask performance:\n",
      "╔══════════╤════════════════════╗\n",
      "║\u001b[1;32m accuracy \u001b[0m│ 0.0000000000000000 ║\n",
      "╚══════════╧════════════════════╝\n",
      "\u001b[1;93m\n",
      "aggregate \u001b[0mtask performance:\n",
      "╔═══════╤════════════════════╗\n",
      "║\u001b[1;36m score \u001b[0m│ 0.0297065850177039 ║\n",
      "╚═══════╧════════════════════╝\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loc_fscore': 0.06211180124223603,\n",
       " 'loc_fscore_shore': 0.08908685968819599,\n",
       " 'vessel_fscore': 0.8292682926829269,\n",
       " 'fishing_fscore': 0.5,\n",
       " 'length_acc': 0.0,\n",
       " 'aggregate': 0.029706585017703884}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(\n",
    "   reference_SLC_predictions, groundtruth_SLC, xView3_SLC_GRD_correspondences, SARFish_root_directory, \"SLC\", \"xView3_shoreline\", \n",
    "    score_all =  False, drop_low_detect = True, costly_dist = True, evaluation_mode = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30d954-5add-4070-8f50-0b1688cf45ce",
   "metadata": {},
   "source": [
    "## 8. How to participate in the SARFish challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc623c2-f98f-48ff-81f4-ccbb8a5ee3a9",
   "metadata": {},
   "source": [
    "Competitors will use the SLC products of the SARFish dataset to generate detection, classification, and vessel length regression models. We are looking for algorithms which exploit the complex data contained in the SLC products. \n",
    "\n",
    "1. Download the SARFish dataset (see section 2)\n",
    "2. Use the train and validation partitions of the SARFish dataset to generate your model (see section 3.1).\n",
    "3. Run inference over the entire public data partition outputing your predictions in submission format (see section 6). \n",
    "4. Submit your predictions in csv format to the [Kaggle](INSERT Kaggle link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
